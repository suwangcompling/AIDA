{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Sentence Similarity\n",
    "\n",
    "** Purpose **\n",
    "\n",
    "We want to make a binary classifier that takes a pair of sentences and judge whether they belong to the same group or not, and then help a downstream cluster (e.g. HAC) w/ it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let $x_1$, $x_2$ be two sentences (encoded in integer indices) of lengths $l_1$, $l_2$ respectively, then we first pad them to be of length $l$, and then embed their consisting words in $d$ dimensional space to produce two matrices $X_1^{l\\times d}, X_2^{l\\times d}$.\n",
    "* We then convolve on the matrices with filters of shapes $(3\\times d), (4\\times d)$ and $(5\\times d)$. This results in vectors of the shape $(l-3+1, 1), (l-4+1, 1)$ and $(l-5+1, 1)$ (with 'VALID', i.e. narrow convolution), for each filter size (i.e. $3, 4$ and $5$). With $k$ filters per filter size, we end up with vectors $((l-3+1)\\times k, 1), ((l-4+1)\\times k, 1)$ and $((l-5+1)\\times k, 1)$. For $x_1$, call them $h_1^3, h_1^4, h_1^5$, on which we do ReLU nonlinearity: $$h = \\texttt{ReLU}(h)$$\n",
    "* Performing max-pooling on the above and concatenate results, we get a single vector representation for each of the two sentences, of shape $(3k,)$, for the two sentences we get $h_{pool1}, h_{pool2}$, we then put them through dropout regularization with probability $p$: $$h_{pool} = \\texttt{Dropout}(h_{pool}, p)$$\n",
    "* Finally we do a bilinear transformation on these vectors to make logits: $$\\texttt{Logit}(x_{pool1}, x_{pool2}) = \\sigma(x_{pool1}^T W^{3k\\times 3k} x_{pool2})$$\n",
    "from which we get the loss $\\mathcal{L}$: $$\\mathcal{L} = \\texttt{Cross-Ent}(\\texttt{Logit}(x_{pool1}, x_{pool2}), y)$$\n",
    "where $y$ is the true label.\n",
    "where \n",
    "* Finally, the prediction is made by rounding the logit: $$\\hat{y} = \\texttt{Round}(\\texttt{Logit}(x_{pool1}, x_{pool2}))$$\n",
    "where $\\texttt{Round}$ returns $1$ if the sigmoid probability is greater than $0.5$ and $0$ otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/jacob.su.wang/Desktop/CODER/TENSORFLOW/SCRIPTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from helpers import Indexer\n",
    "from mock_sentence_similarity import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexer = Indexer()\n",
    "glove_embeddings = get_dict_and_embeddings(VOCAB, indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['dog', 'pig', 'horse', 'horse', 'pig', 'pig', 'deer', 'cat', 'deer',\n",
      "       'horse', 'cat', 'dog', 'horse', 'cat', 'dog', 'horse', 'horse',\n",
      "       'cat', 'dog'],\n",
      "      dtype='<U5'), array(['deer', 'horse', 'dog', 'cat', 'cat', 'deer', 'dog', 'deer',\n",
      "       'horse', 'dog', 'cat', 'horse', 'deer', 'dog', 'cat', 'cat', 'cat',\n",
      "       'pig', 'cat'],\n",
      "      dtype='<U5'))\n",
      "(array(['pig', 'horse', 'dog', 'pig', 'dog', 'horse', 'dog', 'pig', 'cat',\n",
      "       'deer', 'horse', 'pig', 'deer', 'horse'],\n",
      "      dtype='<U5'), array(['bus', 'car', 'car', 'train', 'motorcycle', 'truck', 'motorcycle',\n",
      "       'bus', 'truck', 'train', 'bus', 'bus', 'train', 'train'],\n",
      "      dtype='<U10'))\n"
     ]
    }
   ],
   "source": [
    "print(generate_pos_datum(19))\n",
    "print(generate_neg_datum(14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  0 10 10 10]\n",
      " [ 5  5  8 10 10]]\n",
      "[[ 8  5 10 10 10]\n",
      " [ 6  9  8 10 10]]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "x1, x2, y = generate_batch(indexer, len_from=2, len_to=5, batch_size=2)\n",
    "print(x1)\n",
    "print(x2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "LEN_FROM, LEN_TO = 5, 15\n",
    "MAX_LEN = 15\n",
    "NUM_CLASSES = 2\n",
    "VOCAB_SIZE = len(VOCAB) + 1\n",
    "EMBED_SIZE = 20\n",
    "FILTER_SIZES = [3,4,5]   # size types.\n",
    "NUM_FILTERS = 10         # #filters per size type.\n",
    "NUM_CHANNELS = 1\n",
    "\n",
    "# sess = tf.InteractiveSession()\n",
    "sess = tf.Session()\n",
    "\n",
    "input_x1 = tf.placeholder(tf.int32, [None, MAX_LEN], name='input_x1')\n",
    "input_x2 = tf.placeholder(tf.int32, [None, MAX_LEN], name='input_x2')\n",
    "input_y  = tf.placeholder(tf.int32, [None], name='input_y')\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "with tf.device('/cpu:0'), tf.variable_scope('embeddings'): \n",
    "        # name_scope works only with tf.Variable\n",
    "        # variable_scope works with tf.get_variable\n",
    "    E = tf.get_variable('E', [VOCAB_SIZE, EMBED_SIZE], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    embed_x1 = tf.expand_dims(tf.nn.embedding_lookup(E, input_x1), -1)\n",
    "    embed_x2 = tf.expand_dims(tf.nn.embedding_lookup(E, input_x2), -1)\n",
    "        # embed_x*: [batch_size, height=MAX_LEN, width=EMBED_SIZE, num_channels=1]\n",
    "\n",
    "pool1_outputs, pool2_outputs = [], []\n",
    "for i, filter_size in enumerate(FILTER_SIZES):\n",
    "    with tf.variable_scope('conv-max-pool-%s' % filter_size): \n",
    "        filter_shape = [filter_size, EMBED_SIZE, NUM_CHANNELS, NUM_FILTERS]\n",
    "            # Filter dims: [filter_size, emb_size, num_channels, num_filters]\n",
    "        W1 = tf.get_variable('W1', filter_shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "        W2 = tf.get_variable('W2', filter_shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b1 = tf.get_variable('b1', [NUM_FILTERS], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b2 = tf.get_variable('b2', [NUM_FILTERS], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        conv1 = tf.nn.conv2d(embed_x1, W1, strides=[1,1,1,1], padding='VALID', name='conv1')\n",
    "        conv2 = tf.nn.conv2d(embed_x2, W2, strides=[1,1,1,1], padding='VALID', name='conv2')\n",
    "            # Conv dims: [batch_size, height, width, num_channels]\n",
    "        h1 = tf.nn.relu(tf.nn.bias_add(conv1, b1), name='relu1')\n",
    "        h2 = tf.nn.relu(tf.nn.bias_add(conv2, b2), name='relu2')\n",
    "        pool1 = tf.nn.max_pool(h1, ksize=[1,MAX_LEN-filter_size+1,1,1], strides=[1,1,1,1], padding='VALID', name='pool1')\n",
    "        pool2 = tf.nn.max_pool(h2, ksize=[1,MAX_LEN-filter_size+1,1,1], strides=[1,1,1,1], padding='VALID', name='pool2')\n",
    "            # kernel size (ksize): [batch_size, height, width, num_channels]\n",
    "        pool1_outputs.append(pool1)\n",
    "        pool2_outputs.append(pool2)\n",
    "\n",
    "num_filters_total = NUM_FILTERS * len(FILTER_SIZES)\n",
    "h_pool1_flat = tf.nn.dropout(tf.reshape(tf.concat(pool1_outputs, 3), [-1, num_filters_total]), keep_prob)\n",
    "h_pool2_flat = tf.nn.dropout(tf.reshape(tf.concat(pool2_outputs, 3), [-1, num_filters_total]), keep_prob)\n",
    "    # flat shape: [batch_size, num_filters_total].\n",
    "W_bi = tf.get_variable('W_bi', [num_filters_total, num_filters_total],\n",
    "                       initializer=tf.contrib.layers.xavier_initializer())\n",
    "scores = tf.nn.sigmoid(tf.diag_part(tf.matmul(tf.matmul(h_pool1_flat, W_bi), tf.transpose(h_pool2_flat))))\n",
    "\n",
    "predictions = tf.cast(tf.round(scores), tf.int32, name='predictions')\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    losses = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(input_y, tf.float32), logits=scores)\n",
    "    loss = tf.reduce_mean(losses)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_predictions = tf.equal(predictions, input_y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32), name='accuracy')\n",
    "    \n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1\n",
      "\n",
      "\n",
      "M.Loss = 0.7222447395324707 | M.Accuracy = 0.5165625214576721\n",
      "M.Loss = 0.7139453291893005 | M.Accuracy = 0.510546863079071\n",
      "M.Loss = 0.708305299282074 | M.Accuracy = 0.5075520873069763\n",
      "M.Loss = 0.704450249671936 | M.Accuracy = 0.5064843893051147\n",
      "M.Loss = 0.7013000249862671 | M.Accuracy = 0.5061249732971191\n",
      "M.Loss = 0.6969977021217346 | M.Accuracy = 0.5095833539962769\n",
      "M.Loss = 0.6858866810798645 | M.Accuracy = 0.5452678799629211\n",
      "M.Loss = 0.6687422394752502 | M.Accuracy = 0.5979297161102295\n",
      "M.Loss = 0.652645468711853 | M.Accuracy = 0.6417534947395325\n",
      "M.Loss = 0.638826310634613 | M.Accuracy = 0.6774218678474426\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/jacob.su.wang/Desktop/CODER/TENSORFLOW/CNN/SAVED/cnn-test1-1000'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run model while saving\n",
    "#   1. run init\n",
    "#   2. init tf.train.Saver() object\n",
    "#   3. specify save path\n",
    "#   4. save after sess.run(..) # NB: global_step's imperative\n",
    "\n",
    "NUM_EPOCHS = 1\n",
    "NUM_BATCHES = 1000\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "save_path = '/Users/jacob.su.wang/Desktop/CODER/TENSORFLOW/CNN/SAVED/cnn-test1'\n",
    "\n",
    "for e in range(NUM_EPOCHS):\n",
    "    print('Epoch ', e+1)\n",
    "    print('\\n')\n",
    "    loss_track, accuracy_track = [], []\n",
    "    for b in range(NUM_BATCHES):\n",
    "        batch_x1, batch_x2, batch_y = generate_batch(indexer, LEN_FROM, LEN_TO, batch_size=64)\n",
    "        fd = {input_x1:batch_x1, input_x2:batch_x2, input_y:batch_y, keep_prob:0.7}\n",
    "        _, step, loss_, accuracy_ = sess.run([train_op, global_step, loss, accuracy], feed_dict=fd)\n",
    "        loss_track.append(loss_)\n",
    "        accuracy_track.append(accuracy_)\n",
    "        if step%100==0:\n",
    "            print('M.Loss = {} | M.Accuracy = {}'.format(np.mean(loss_track), np.mean(accuracy_track)))\n",
    "    print('\\n')\n",
    "    \n",
    "saver.save(sess, save_path, sess.run(global_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Restore the stuff\n",
    "#   1. init sess\n",
    "#   2. get graph using tf.train.import_meta_graph(path/to/meta)\n",
    "#   3. use obj created in step 2 to restore from check point\n",
    "#   4. build a graph using tf.get_default_graph()\n",
    "#   5. read input-end tensors (the shit you create feed_dict by) # don't forget naming.\n",
    "#   6. read output-end tensors # don't forget naming.\n",
    "#   7. run output-end tensor as usual\n",
    "\n",
    "sess = tf.Session()\n",
    "saver = tf.train.import_meta_graph(save_path+'-1000.meta')\n",
    "saver.restore(sess, tf.train.latest_checkpoint('/Users/jacob.su.wang/Desktop/CODER/TENSORFLOW/CNN/SAVED/'))\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "input_x1 = graph.get_tensor_by_name('input_x1:0')\n",
    "input_x2 = graph.get_tensor_by_name('input_x2:0')\n",
    "keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
    "\n",
    "test_x1 = [['motorcycle', 'train', 'motorcycle', 'car', 'car', 'car', 'train']]\n",
    "test_x2 = [['motorcycle', 'train', 'train', 'car', 'bus']]\n",
    "test_x3 = [['cat', 'cat', 'deer', 'deer', 'pig', 'dog', 'dog', 'deer', 'dog']]\n",
    "def to_code(x_):\n",
    "    return [[indexer.get_index(elem) for elem in pad_sentence(MAX_LEN, x_[0])]]\n",
    "fd = {input_x1:to_code(test_x1), input_x2:to_code(test_x2), keep_prob:1.0}\n",
    "\n",
    "predictions = graph.get_tensor_by_name('predictions:0')\n",
    "print(sess.run(predictions, feed_dict=fd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cust. Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test x1 = x2; test x3 in another group.\n",
    "test_x1 = [['motorcycle', 'train', 'motorcycle', 'car', 'car', 'car', 'train']]\n",
    "test_x2 = [['motorcycle', 'train', 'train', 'car', 'bus']]\n",
    "test_x3 = [['cat', 'cat', 'deer', 'deer', 'pig', 'dog', 'dog', 'deer', 'dog']]\n",
    "test_y12 = [1]\n",
    "test_y13 = [0]\n",
    "test_y23 = [0]\n",
    "\n",
    "def to_code(x_):\n",
    "    return [[indexer.get_index(elem) for elem in pad_sentence(MAX_LEN, x_[0])]]\n",
    "\n",
    "def predict(x1_, x2_, y_, sess_):\n",
    "    fd = {input_x1:to_code(x1_), input_x2:to_code(x2_), input_y:test_y12, keep_prob:1.0}\n",
    "    pred, conf = sess_.run([predictions, scores], feed_dict=fd)\n",
    "    print('True = {} | Pred = {} (conf: {})'.format(y_, pred, conf if y_==[1] else 1-conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True = [1] | Pred = [1] (conf: [ 0.98743469])\n",
      "True = [0] | Pred = [0] (conf: [ 0.99620718])\n",
      "True = [0] | Pred = [0] (conf: [ 0.99533159])\n"
     ]
    }
   ],
   "source": [
    "predict(test_x1, test_x2, test_y12, sess)\n",
    "predict(test_x1, test_x3, test_y13, sess)\n",
    "predict(test_x2, test_x3, test_y23, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 1, 7, 0, 0, 0, 1, 10, 10, 10, 10, 10, 10, 10, 10]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_code(test_x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HAC w/ CNN sentence distance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7, 1, 7, 0, 0, 0, 1, 10, 10, 10, 10, 10, 10, 10, 10], [7, 1, 1, 0, 2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], [6, 6, 8, 8, 9, 5, 5, 8, 5, 10, 10, 10, 10, 10, 10]]\n",
      "\n",
      "\n",
      "0.995331563987\n"
     ]
    }
   ],
   "source": [
    "# Test run\n",
    "\n",
    "X = to_code(test_x1) + to_code(test_x2) + to_code(test_x3)\n",
    "    # x1, x2: vehicle sentence, x3: animal sentence.\n",
    "print(X); print('\\n')\n",
    "\n",
    "def mydist(p1, p2):\n",
    "    fd = {input_x1:[p1], input_x2:[p2], keep_prob:1.0}\n",
    "    conf = sess.run(scores, feed_dict=fd)\n",
    "    return 1-conf[0] # predict 0 means two sentences a far\n",
    "\n",
    "print(mydist(X[1],X[2])) # expect far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mock run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "def foo(n=5):\n",
    "    # Generate some data\n",
    "    # data: original strings\n",
    "    # data_code: encoded data strings by indexer\n",
    "    data = []\n",
    "    data_code = []\n",
    "    for _ in range(n):\n",
    "        a_,b_ = generate_neg_datum(5)\n",
    "        data += [a_, b_]\n",
    "        data_code += [to_code_foo(a_), to_code_foo(b_)]\n",
    "    return data, data_code\n",
    "\n",
    "def to_code_foo(x_):\n",
    "    return [indexer.get_index(elem) for elem in pad_sentence(MAX_LEN, x_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2 = foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, array(['bus', 'truck', 'motorcycle', 'truck', 'train'],\n",
      "      dtype='<U10')), (1, array(['pig', 'deer', 'dog', 'dog', 'deer'],\n",
      "      dtype='<U5')), (2, array(['horse', 'horse', 'cat', 'horse', 'horse'],\n",
      "      dtype='<U5')), (3, array(['motorcycle', 'motorcycle', 'bus', 'train', 'bus'],\n",
      "      dtype='<U10')), (4, array(['truck', 'truck', 'truck', 'motorcycle', 'car'],\n",
      "      dtype='<U10')), (5, array(['horse', 'deer', 'pig', 'pig', 'cat'],\n",
      "      dtype='<U5')), (6, array(['horse', 'cat', 'pig', 'pig', 'dog'],\n",
      "      dtype='<U5')), (7, array(['train', 'train', 'car', 'motorcycle', 'bus'],\n",
      "      dtype='<U10')), (8, array(['motorcycle', 'train', 'bus', 'truck', 'bus'],\n",
      "      dtype='<U10')), (9, array(['horse', 'deer', 'pig', 'cat', 'dog'],\n",
      "      dtype='<U5'))]\n"
     ]
    }
   ],
   "source": [
    "print(list(enumerate(X1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 7, 3, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       " [9, 8, 5, 5, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       " [4, 4, 6, 4, 4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       " [7, 7, 2, 1, 2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       " [3, 3, 3, 7, 0, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       " [4, 8, 9, 9, 6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       " [4, 6, 9, 9, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       " [1, 1, 0, 7, 2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       " [7, 1, 2, 3, 2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       " [4, 8, 9, 6, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0241961479187\n",
      "0.977911744267\n"
     ]
    }
   ],
   "source": [
    "print(mydist(X2[0],X2[3])) # expect close\n",
    "print(mydist(X2[0],X2[1])) # expect far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=5, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = linkage(X2, metric=mydist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.     ,   5.     ,   0.00294,   2.     ],\n",
       "       [  9.     ,  10.     ,   0.00373,   3.     ],\n",
       "       [  3.     ,   8.     ,   0.00579,   2.     ],\n",
       "       [  6.     ,  11.     ,   0.00667,   4.     ],\n",
       "       [  7.     ,  12.     ,   0.01347,   3.     ],\n",
       "       [  0.     ,  14.     ,   0.01549,   4.     ],\n",
       "       [  4.     ,  15.     ,   0.02349,   5.     ],\n",
       "       [  2.     ,  13.     ,   0.03558,   5.     ],\n",
       "       [ 16.     ,  17.     ,   0.92439,  10.     ]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format of clustering results\n",
    "#   [idx1, idx2, dist, sample_count]\n",
    "#   idx1, idx2: cluster ids\n",
    "#   idx1 and idx2 are merged with distance to create a cluster of size sample_count.\n",
    "Z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABakAAAJcCAYAAADzQijuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b575dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate full dendrogram\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "dendrogram(\n",
    "    Z,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=15.,  # font size for the x axis labels\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As you can see, the separation is pretty dope.\n",
    "\n",
    "# [(0, array(['bus', 'truck', 'motorcycle', 'truck', 'train'],\n",
    "#       dtype='<U10')), (1, array(['pig', 'deer', 'dog', 'dog', 'deer'],\n",
    "#       dtype='<U5')), (2, array(['horse', 'horse', 'cat', 'horse', 'horse'],\n",
    "#       dtype='<U5')), (3, array(['motorcycle', 'motorcycle', 'bus', 'train', 'bus'],\n",
    "#       dtype='<U10')), (4, array(['truck', 'truck', 'truck', 'motorcycle', 'car'],\n",
    "#       dtype='<U10')), (5, array(['horse', 'deer', 'pig', 'pig', 'cat'],\n",
    "#       dtype='<U5')), (6, array(['horse', 'cat', 'pig', 'pig', 'dog'],\n",
    "#       dtype='<U5')), (7, array(['train', 'train', 'car', 'motorcycle', 'bus'],\n",
    "#       dtype='<U10')), (8, array(['motorcycle', 'train', 'bus', 'truck', 'bus'],\n",
    "#       dtype='<U10')), (9, array(['horse', 'deer', 'pig', 'cat', 'dog'],\n",
    "#       dtype='<U5'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
