{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role-factored Tensor Net\n",
    "\n",
    "* Adapted from Weber et al. (2018) Event Representations with Tensor-based Compositions. AAAI18\n",
    "\n",
    "* INPUT: a batch of events (5-tuples $\\texttt{<v,s,o,p,po>}$), corresponding positive and negative instances (word2vec style training).\n",
    "* OUTPUT: encoded event representation (as vectors).\n",
    "* PROC:\n",
    "    * Modeling the interaction between the predicate v with each of the arguments (equation: same for other args)\n",
    "    $$v_s = v\\cdot T\\cdot s^{T}$$\n",
    "    where $v\\in R^{b\\times d_e}$, $T\\in R^{d_e,d_e,h}$, and $s\\in R^{b\\times d_e}$. This results in a batch of event vectors $\\in R^{b,h}$ after batch matching and transposing.\n",
    "    * Merging factor interactions additively\n",
    "    $$e = v_s\\cdot W_s + \\dots + v_{po}\\cdot W_{po}$$\n",
    "    * Maximizing the distance between the input event and its positive examples while minimizing the distance between it and its negative examples through a max-margin loss\n",
    "    $$\\ell = \\frac{1}{N}\\sum_{i=1}^N \\texttt{max}(0, m + \\texttt{sim}(e, e_{neg}) - \\texttt{sim}(e, e_{pos}))$$\n",
    "* COMMENTS\n",
    "    * For the simple demo I use dot product for distance metric rather than cosine as in the paper.\n",
    "    * The network is not L2-regularized as in the paper, but the loss term can be easily added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/work/04233/sw33286/AIDA-SCRIPTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from helpers import Indexer\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77277, 300)\n"
     ]
    }
   ],
   "source": [
    "# Link to NYT data folder\n",
    "\n",
    "nyt_code_dir = \"/work/04233/sw33286/AIDA-DATA/nyt_eng_salads_event_code/\"\n",
    "FILE_NAMES = os.listdir(nyt_code_dir)\n",
    "\n",
    "# Link to dictionary information\n",
    "\n",
    "info_path = \"/work/04233/sw33286/AIDA-DATA/nyt_eng_salads_info/indexer_word2emb_100k_event.p\"\n",
    "indexer100k, word2emb100k = dill.load(open(info_path, 'rb'))\n",
    "glove_embs = []\n",
    "for i in range(len(indexer100k)):\n",
    "    glove_embs.append(word2emb100k[indexer100k.get_object(i)])\n",
    "glove_embs = np.array(glove_embs)\n",
    "print(glove_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "CONTRA_BC = 10\n",
    "\n",
    "def get_batch(edoc_a, edoc_b):\n",
    "    edoc_a = list(chain.from_iterable(edoc_a)) # to a list of events\n",
    "    edoc_b = list(chain.from_iterable(edoc_b))\n",
    "    size_a, size_b = len(edoc_a), len(edoc_b)\n",
    "    batch_x, batch_pos, batch_neg = [], [], []\n",
    "    for _ in range(BATCH_SIZE//2):\n",
    "        x_a = edoc_a[np.random.randint(0, size_a)]\n",
    "        x_b = edoc_b[np.random.randint(0, size_b)]\n",
    "        pos_a = [edoc_a[np.random.randint(0, size_a)] for _ in range(CONTRA_BC)]\n",
    "        neg_a = [edoc_b[np.random.randint(0, size_b)] for _ in range(CONTRA_BC)]\n",
    "        pos_b = [edoc_b[np.random.randint(0, size_b)] for _ in range(CONTRA_BC)]\n",
    "        neg_b = [edoc_a[np.random.randint(0, size_a)] for _ in range(CONTRA_BC)]        \n",
    "        batch_x += [x_a, x_b]\n",
    "        batch_pos += [pos_a, pos_b]\n",
    "        batch_neg += [neg_a, neg_b]\n",
    "    return np.array(batch_x), np.array(batch_pos), np.array(batch_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 5), (32, 10, 5), (32, 10, 5))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: batch shapes\n",
    "\n",
    "edoc_a, edoc_b, _ = dill.load(open(nyt_code_dir+FILE_NAMES[0],'rb'))\n",
    "a,b1,b2 = get_batch(edoc_a, edoc_b)\n",
    "a.shape, b1.shape, b2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role-factored Tensor Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "VOCAB_SIZE, EMB_SIZE = glove_embs.shape\n",
    "HID_SIZE = 100 # let event embs be of the same hid-size as role-factored arg vectors.\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# for debugging, explicit batch-size:\n",
    "# inputs = tf.placeholder(tf.int32, [BATCH_SIZE, 5], name='inputs') # <bc,nw-in-event=5>\n",
    "# inputs_pos = tf.placeholder(tf.int32, [BATCH_SIZE, CONTRA_BC, 5], name='inputs_pos') # <bc,ctr-bc,nw-in-event=5>\n",
    "# inputs_neg = tf.placeholder(tf.int32, [BATCH_SIZE, CONTRA_BC, 5], name='inputs_neg')\n",
    "\n",
    "inputs = tf.placeholder(tf.int32, [None, 5], name='inputs') # <bc,nw-in-event=5>\n",
    "inputs_pos = tf.placeholder(tf.int32, [None, CONTRA_BC, 5], name='inputs_pos') # <bc,ctr-bc,nw-in-event=5>\n",
    "inputs_neg = tf.placeholder(tf.int32, [None, CONTRA_BC, 5], name='inputs_neg')\n",
    "    # NB: make sure the three Nones equal.\n",
    "\n",
    "with tf.variable_scope('Embedding'):\n",
    "    embeddings = tf.get_variable('embedding', [VOCAB_SIZE, EMB_SIZE],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "    glove_init = embeddings.assign(glove_embs)\n",
    "\n",
    "with tf.variable_scope('Role-factor'):\n",
    "    T = tf.get_variable('T', [EMB_SIZE, EMB_SIZE, HID_SIZE], \n",
    "                        initializer=tf.contrib.layers.xavier_initializer())\n",
    "    W_s = tf.get_variable('W_s', [HID_SIZE, HID_SIZE], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    W_o = tf.get_variable('W_o', [HID_SIZE, HID_SIZE], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    W_p = tf.get_variable('W_p', [HID_SIZE, HID_SIZE], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    W_po = tf.get_variable('W_po', [HID_SIZE, HID_SIZE], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "def encode_events(inputs_):\n",
    "    bc,_ = tf.unstack(tf.shape(inputs_))\n",
    "    # Slicing inputs\n",
    "    input_v = tf.squeeze(tf.slice(inputs_, [0,0],[bc,1]), -1)\n",
    "        # op1. looking up the vector corresponds to the predicate: <bc,1>\n",
    "        # op2. get rid of the vacuous dimension: <bc,>\n",
    "    input_s = tf.squeeze(tf.slice(inputs_, [0,1],[bc,1]))\n",
    "    input_o = tf.squeeze(tf.slice(inputs_, [0,2],[bc,1]))\n",
    "    input_p = tf.squeeze(tf.slice(inputs_, [0,3],[bc,1]))\n",
    "    input_po = tf.squeeze(tf.slice(inputs_, [0,4],[bc,1]))\n",
    "    # Looking up\n",
    "    input_v_embedded = tf.nn.embedding_lookup(embeddings, input_v) # <bc,emb>\n",
    "    input_s_embedded = tf.transpose(tf.nn.embedding_lookup(embeddings, input_s),[1,0]) # <emb,bc>\n",
    "    input_o_embedded = tf.transpose(tf.nn.embedding_lookup(embeddings, input_o),[1,0])\n",
    "    input_p_embedded = tf.transpose(tf.nn.embedding_lookup(embeddings, input_p),[1,0])\n",
    "    input_po_embedded = tf.transpose(tf.nn.embedding_lookup(embeddings, input_po),[1,0])\n",
    "    # Role factoring\n",
    "    vT = tf.transpose(tf.tensordot(input_v_embedded, T, axes=[[1],[0]]), [0,2,1])\n",
    "        # op1. <bc,emb> * <emb,emb,hid> -> <bc,emb,hid>\n",
    "        # op2. <bc,emb,hid> -> <bc,hid,emb>\n",
    "    vTs = tf.matrix_diag_part(tf.transpose(tf.tensordot(vT, input_s_embedded, axes=[[2],[0]]), [1,0,2]))\n",
    "        # op1. <bc,hid,emb> * <emb,bc> -> <bc,hid,bc>\n",
    "        # op2. <bc,hid,bc> -> <hid,bc,bc>\n",
    "        # op3. <hid,bc>\n",
    "    vTo = tf.matrix_diag_part(tf.transpose(tf.tensordot(vT, input_o_embedded, axes=[[2],[0]]), [1,0,2]))\n",
    "    vTp = tf.matrix_diag_part(tf.transpose(tf.tensordot(vT, input_p_embedded, axes=[[2],[0]]), [1,0,2]))\n",
    "    vTpo = tf.matrix_diag_part(tf.transpose(tf.tensordot(vT, input_po_embedded, axes=[[2],[0]]), [1,0,2]))\n",
    "    # Factor merging\n",
    "    v_s = tf.matmul(W_s, vTs) # <hid,hid> * <hid,bc> -> <hid,bc>\n",
    "    v_o = tf.matmul(W_p, vTo)\n",
    "    v_p = tf.matmul(W_o, vTp)\n",
    "    v_po = tf.matmul(W_po, vTpo)\n",
    "    v_event = v_s + v_o + v_p + v_po # <hid,bc>\n",
    "    return v_event\n",
    "\n",
    "inputs_encoded = encode_events(inputs) # <hid,bc>\n",
    "inputs_pos_encoded = tf.transpose(tf.map_fn(encode_events, inputs_pos, dtype=tf.float32), [0,2,1]) # <bc,hid,ctr-bc>\n",
    "    # op1. event-encoder output: <bc,hid,ctr-bc>\n",
    "    # op2. transpose: <bc,ctr-bc,hid>\n",
    "inputs_neg_encoded = tf.transpose(tf.map_fn(encode_events, inputs_neg, dtype=tf.float32), [0,2,1])\n",
    "\n",
    "with tf.variable_scope('Encode'):\n",
    "    predictions = tf.transpose(inputs_encoded, [1,0], name='predictions') # to <bc,hid> for convenience.\n",
    "\n",
    "with tf.variable_scope('Loss'):\n",
    "    sim_pos = tf.matrix_diag_part(tf.transpose(tf.tensordot(inputs_pos_encoded, inputs_encoded, axes=[[2],[0]]), \n",
    "                                               [1,0,2]))\n",
    "        # op1. tensordot: <bc,ctr-bc,hid> * <hid,bc> -> <bc,ctr-bc,bc>\n",
    "        # op2. transpose: <ctr-bc,bc,bc>\n",
    "        # op3. match bc: <ctr-bc,bc>\n",
    "    sim_neg = tf.matrix_diag_part(tf.transpose(tf.tensordot(inputs_neg_encoded, inputs_encoded, axes=[[2],[0]]), \n",
    "                                               [1,0,2]))    \n",
    "    loss = tf.reduce_mean(tf.reduce_mean(tf.maximum(0., 1. + sim_neg - sim_pos), axis=0), name='loss')\n",
    "        # op1. max(0, m + sim_neg - sim_pos), <ctr-bc,bc>\n",
    "        # op2. average loss over contra instances: <bc,>\n",
    "        # op3. average loss over batch\n",
    "        \n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "optimizer = tf.train.AdamOptimizer(LEARNING_RATE)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step, name='train_op')\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def remove_all_files(target_dir):\n",
    "    for filename in os.listdir(target_dir):\n",
    "        os.remove(os.path.abspath(os.path.join(target_dir, filename)))\n",
    "        \n",
    "def checkpoint_model(s_dir, s_path, svr, ss):\n",
    "    # save_dir, save_path, saver, sess\n",
    "    remove_all_files(s_dir)\n",
    "    svr.save(ss, s_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "TRAIN_SIZE = 10\n",
    "VERBOSE = 1\n",
    "SAVE_PER = 50000\n",
    "# TRAIN_SIZE = len(FILE_NAMES)\n",
    "# VERBOSE = 10\n",
    "\n",
    "try:\n",
    "    loss_track = []\n",
    "    for e in range(NUM_EPOCHS):\n",
    "        print('Epoch ', e+1)\n",
    "        print('\\n')\n",
    "        curr_loss_track = []\n",
    "        file_indices = np.random.choice(list(range(len(FILE_NAMES))), size=TRAIN_SIZE, replace=False)\n",
    "        random.shuffle(file_indices)\n",
    "        curr_loss_track, curr_accuracy_track = [], []\n",
    "        for file_idx in file_indices:\n",
    "            edoc_a, edoc_b, _ = dill.load(open(nyt_code_dir+FILE_NAMES[file_idx],'rb')) # context not added\n",
    "            batch_x, batch_pos, batch_neg = get_batch(edoc_a, edoc_b)\n",
    "            fd = {inputs:batch_x, inputs_pos:batch_pos, inputs_neg:batch_neg}\n",
    "            _, step, loss_ = sess.run([train_op, global_step, loss], feed_dict=fd)\n",
    "            curr_loss_track.append(loss_)\n",
    "            if step%VERBOSE==0:\n",
    "                print(' average batch loss at step {}: <{}>'.format(step, np.mean(curr_loss_track)))\n",
    "            if step%SAVE_PER==0:\n",
    "                checkpoint_model(save_dir, save_path, saver, sess)\n",
    "                print(' [SAVE] model checkpointed at step {}'.format(step))\n",
    "        print('\\n')\n",
    "        print('  epoch mean loss: <{}>'.format(np.mean(curr_loss_track)))\n",
    "        print('\\n') \n",
    "        loss_track += curr_loss_track  \n",
    "except KeyboardInterrupt:\n",
    "    print('Stopped!')                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/work/04233/sw33286/AIDA-INDIV-MODEL-SAVE-EVENT/our-model-rf-pretrain/\"\n",
    "save_path = save_dir + \"our-model-rf-pretrain-00\"\n",
    "checkpoint_model(save_dir, save_path, saver, sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling continued training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77277, 300)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/work/04233/sw33286/AIDA-SCRIPTS\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from helpers import Indexer\n",
    "from itertools import chain\n",
    "\n",
    "# Link to NYT data folder\n",
    "\n",
    "nyt_code_dir = \"/work/04233/sw33286/AIDA-DATA/nyt_eng_salads_event_code/\"\n",
    "FILE_NAMES = os.listdir(nyt_code_dir)\n",
    "\n",
    "# Link to dictionary information\n",
    "\n",
    "info_path = \"/work/04233/sw33286/AIDA-DATA/nyt_eng_salads_info/indexer_word2emb_100k_event.p\"\n",
    "indexer100k, word2emb100k = dill.load(open(info_path, 'rb'))\n",
    "glove_embs = []\n",
    "for i in range(len(indexer100k)):\n",
    "    glove_embs.append(word2emb100k[indexer100k.get_object(i)])\n",
    "glove_embs = np.array(glove_embs)\n",
    "print(glove_embs.shape)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "CONTRA_BC = 10\n",
    "\n",
    "def get_batch(edoc_a, edoc_b):\n",
    "    edoc_a = list(chain.from_iterable(edoc_a)) # to a list of events\n",
    "    edoc_b = list(chain.from_iterable(edoc_b))\n",
    "    size_a, size_b = len(edoc_a), len(edoc_b)\n",
    "    batch_x, batch_pos, batch_neg = [], [], []\n",
    "    for _ in range(BATCH_SIZE//2):\n",
    "        x_a = edoc_a[np.random.randint(0, size_a)]\n",
    "        x_b = edoc_b[np.random.randint(0, size_b)]\n",
    "        pos_a = [edoc_a[np.random.randint(0, size_a)] for _ in range(CONTRA_BC)]\n",
    "        neg_a = [edoc_b[np.random.randint(0, size_b)] for _ in range(CONTRA_BC)]\n",
    "        pos_b = [edoc_b[np.random.randint(0, size_b)] for _ in range(CONTRA_BC)]\n",
    "        neg_b = [edoc_a[np.random.randint(0, size_a)] for _ in range(CONTRA_BC)]        \n",
    "        batch_x += [x_a, x_b]\n",
    "        batch_pos += [pos_a, pos_b]\n",
    "        batch_neg += [neg_a, neg_b]\n",
    "    return np.array(batch_x), np.array(batch_pos), np.array(batch_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_dir = \"/work/04233/sw33286/AIDA-INDIV-MODEL-SAVE-EVENT/our-model-rf-pretrain/\"\n",
    "restore_filename = \"our-model-rf-pretrain-00.meta\"\n",
    "\n",
    "sess = tf.Session()\n",
    "saver = tf.train.import_meta_graph(restore_dir + restore_filename)\n",
    "saver.restore(sess, tf.train.latest_checkpoint(restore_dir))\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "inputs = graph.get_tensor_by_name('inputs:0')\n",
    "inputs_pos = graph.get_tensor_by_name('inputs_pos:0')\n",
    "inputs_neg = graph.get_tensor_by_name('inputs_neg:0')\n",
    "\n",
    "loss = graph.get_tensor_by_name('Loss/loss:0')\n",
    "global_step = graph.get_tensor_by_name('global_step:0')\n",
    "train_op = graph.get_tensor_by_name('train_op:0')\n",
    "\n",
    "save_dir = \"/work/04233/sw33286/AIDA-INDIV-MODEL-SAVE-EVENT/our-model-rf-pretrain/\"\n",
    "save_path = save_dir + \"our-model-rf-pretrain-00\"\n",
    "\n",
    "def remove_all_files(target_dir):\n",
    "    for filename in os.listdir(target_dir):\n",
    "        os.remove(os.path.abspath(os.path.join(target_dir, filename)))\n",
    "        \n",
    "def checkpoint_model(s_dir, s_path, svr, ss):\n",
    "    # save_dir, save_path, saver, sess\n",
    "    remove_all_files(s_dir)\n",
    "    svr.save(ss, s_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "# TRAIN_SIZE = 10\n",
    "# VERBOSE = 1\n",
    "SAVE_PER = 50000\n",
    "TRAIN_SIZE = len(FILE_NAMES)\n",
    "VERBOSE = 10\n",
    "\n",
    "try:\n",
    "    loss_track = []\n",
    "    for e in range(NUM_EPOCHS):\n",
    "        print('Epoch ', e+1)\n",
    "        print('\\n')\n",
    "        curr_loss_track = []\n",
    "        file_indices = np.random.choice(list(range(len(FILE_NAMES))), size=TRAIN_SIZE, replace=False)\n",
    "        random.shuffle(file_indices)\n",
    "        curr_loss_track, curr_accuracy_track = [], []\n",
    "        for file_idx in file_indices:\n",
    "            edoc_a, edoc_b, _ = dill.load(open(nyt_code_dir+FILE_NAMES[file_idx],'rb')) # context not added\n",
    "            batch_x, batch_pos, batch_neg = get_batch(edoc_a, edoc_b)\n",
    "            fd = {inputs:batch_x, inputs_pos:batch_pos, inputs_neg:batch_neg}\n",
    "            _, step, loss_ = sess.run([train_op, global_step, loss], feed_dict=fd)\n",
    "            curr_loss_track.append(loss_)\n",
    "            if step%VERBOSE==0:\n",
    "                print(' average batch loss at step {}: <{}>'.format(step, np.mean(curr_loss_track)))\n",
    "            if step%SAVE_PER==0:\n",
    "                checkpoint_model(save_dir, save_path, saver, sess)\n",
    "                print(' [SAVE] model checkpointed at step {}'.format(step))\n",
    "        print('\\n')\n",
    "        print('  epoch mean loss: <{}>'.format(np.mean(curr_loss_track)))\n",
    "        print('\\n') \n",
    "        loss_track += curr_loss_track  \n",
    "except KeyboardInterrupt:\n",
    "    print('Stopped!')                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "\n",
    "checkpoint_model(save_dir, save_path, saver, sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class BasicRoleFactored:\n",
    "    # basic:\n",
    "    #   - not l2-regularized or dropout-regularized.\n",
    "    #   - dot Ã  la place de cosine.\n",
    "    \n",
    "    def __init__(self, rf_dir, rf_filename):\n",
    "        self.sess = tf.Session()\n",
    "        saver = tf.train.import_meta_graph(rf_dir + rf_filename)\n",
    "        saver.restore(self.sess, tf.train.latest_checkpoint(rf_dir))\n",
    "        self.graph = tf.get_default_graph()\n",
    "        self.inputs = self.graph.get_tensor_by_name('inputs:0') # <bc,nw-in-event=5>\n",
    "        self.predictions = self.graph.get_tensor_by_name('Encode/predictions:0') # <bc,hid>\n",
    "            # hid=100 hard coded for now.\n",
    "    \n",
    "    def embed_batch(self, batch_events):\n",
    "        return self.sess.run(self.predictions, feed_dict={self.inputs:batch_events})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_dir = \"/work/04233/sw33286/AIDA-INDIV-MODEL-SAVE-EVENT/our-model-rf-pretrain/\"\n",
    "restore_filename = \"our-model-rf-pretrain-00.meta\"\n",
    "brf = BasicRoleFactored(restore_dir, restore_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input event batch shape: 32 x 5\n",
      "Output event batch shape: 32 x 100\n"
     ]
    }
   ],
   "source": [
    "# Example: batch shapes\n",
    "\n",
    "edoc_a, edoc_b, _ = dill.load(open(nyt_code_dir+FILE_NAMES[0],'rb'))\n",
    "a,_,_ = get_batch(edoc_a, edoc_b) # only want <bc,nw-in-event=5> output\n",
    "print(\"Input event batch shape: {} x {}\".format(*a.shape))\n",
    "b = brf.embed_batch(a)\n",
    "print(\"Output event batch shape: {} x {}\".format(*b.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
