{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN event-pair pretraining\n",
    "\n",
    "* Baseline naive-FFNN for Weber et al. (2018) Event Representations with Tensor-based Compositions. AAAI18\n",
    "\n",
    "* INPUT: a batch of events (5-tuples <v,s,o,p,po>), corresponding positive and negative instances (word2vec style training).\n",
    "* OUTPUT: encoded event representation (as vectors).\n",
    "* PROC:\n",
    "    * Look up word embeddings and concat embeddings within events. An event is thus a vector $e\\in R^{5d_e}$\n",
    "    * Put event embeddings through a feedforward layer for encoding\n",
    "    $$v_e = e\\cdot W$$\n",
    "    where $W\\in R^{5d_e\\times h}$.\n",
    "    * Maximizing the distance between the input event and its positive examples while minimizing the distance between it and its negative examples through a max-margin loss\n",
    "    $$\\ell = \\frac{1}{N}\\sum_{i=1}^N \\texttt{max}(0, m + \\texttt{sim}(e, e_{neg}) - \\texttt{sim}(e, e_{pos}))$$\n",
    "* COMMENTS\n",
    "    * For the simple demo I use dot product for distance metric rather than cosine as in the paper.\n",
    "    * The network is not L2-regularized as in the paper, but the loss term can be easily added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/work/04233/sw33286/AIDA-SCRIPTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from helpers import Indexer\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100001, 300)\n"
     ]
    }
   ],
   "source": [
    "# Link to NYT data folder\n",
    "\n",
    "nyt_code_dir = \"/work/04233/sw33286/AIDA-DATA/nyt_eng_salads_event_sample_code/\"\n",
    "FILE_NAMES = os.listdir(nyt_code_dir)\n",
    "\n",
    "# Link to dictionary information\n",
    "\n",
    "info_path = \"/work/04233/sw33286/AIDA-DATA/nyt_eng_salads_info/indexer_word2emb_100k.p\"\n",
    "indexer100k, word2emb100k = dill.load(open(info_path, 'rb'))\n",
    "glove_embs = []\n",
    "for i in range(len(indexer100k)):\n",
    "    glove_embs.append(word2emb100k[indexer100k.get_object(i)])\n",
    "glove_embs = np.array(glove_embs)\n",
    "print(glove_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "CONTRA_BC = 10\n",
    "NUM_WORDS = 5\n",
    "\n",
    "def get_batch(edoc_a, edoc_b):\n",
    "    edoc_a = list(chain.from_iterable(edoc_a)) # to a list of events\n",
    "    edoc_b = list(chain.from_iterable(edoc_b))\n",
    "    size_a, size_b = len(edoc_a), len(edoc_b)\n",
    "    batch_x, batch_pos, batch_neg = [], [], []\n",
    "    for _ in range(BATCH_SIZE//2):\n",
    "        x_a = edoc_a[np.random.randint(0, size_a)]\n",
    "        x_b = edoc_b[np.random.randint(0, size_b)]\n",
    "        pos_a = [edoc_a[np.random.randint(0, size_a)] for _ in range(CONTRA_BC)]\n",
    "        neg_a = [edoc_b[np.random.randint(0, size_b)] for _ in range(CONTRA_BC)]\n",
    "        pos_b = [edoc_b[np.random.randint(0, size_b)] for _ in range(CONTRA_BC)]\n",
    "        neg_b = [edoc_a[np.random.randint(0, size_a)] for _ in range(CONTRA_BC)]        \n",
    "        batch_x += [x_a, x_b]\n",
    "        batch_pos += [pos_a, pos_b]\n",
    "        batch_neg += [neg_a, neg_b]\n",
    "    return np.array(batch_x), np.array(batch_pos), np.array(batch_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 5), (32, 10, 5), (32, 10, 5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: batch shapes\n",
    "\n",
    "edoc_a, edoc_b, _ = dill.load(open(nyt_code_dir+FILE_NAMES[0],'rb'))\n",
    "a,b1,b2 = get_batch(edoc_a, edoc_b)\n",
    "a.shape, b1.shape, b2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN event-pair sem-space learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "VOCAB_SIZE, EMB_SIZE = glove_embs.shape\n",
    "HID_SIZE = 100 # let event embs be of the same hid-size as role-factored arg vectors.\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# for debugging, explicit batch-size:\n",
    "inputs = tf.placeholder(tf.int32, [BATCH_SIZE, 5], name='inputs') # <bc,nw-in-event=5>\n",
    "inputs_pos = tf.placeholder(tf.int32, [BATCH_SIZE, CONTRA_BC, 5], name='inputs_pos') # <bc,ctr-bc,nw-in-event=5>\n",
    "inputs_neg = tf.placeholder(tf.int32, [BATCH_SIZE, CONTRA_BC, 5], name='inputs_neg')\n",
    "\n",
    "with tf.variable_scope('Embedding'):\n",
    "    embeddings = tf.get_variable('embedding', [VOCAB_SIZE, EMB_SIZE],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "    glove_init = embeddings.assign(glove_embs)\n",
    "    \n",
    "with tf.variable_scope('Concat-encode'):\n",
    "    W = tf.get_variable('W', [NUM_WORDS*EMB_SIZE, HID_SIZE], \n",
    "                        initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "def encode_events(inputs_):\n",
    "    bc,_ = tf.unstack(tf.shape(inputs_))\n",
    "    embedded = tf.reshape(tf.nn.embedding_lookup(embeddings, inputs_), [bc,-1])\n",
    "        # op1. lookup: <bc,nw,emb>\n",
    "        # op2. concat word embs in event: <bc,nw*emb>\n",
    "    return tf.matmul(embedded, W) # <bc,nw*emb> * <nw*emb,hid> -> <bc,hid>\n",
    "\n",
    "inputs_encoded = encode_events(inputs) # <bc,hid>\n",
    "inputs_pos_encoded = tf.map_fn(encode_events, inputs_pos, dtype=tf.float32) # <bc,ctr,hid>\n",
    "inputs_neg_encoded = tf.map_fn(encode_events, inputs_neg, dtype=tf.float32)\n",
    "\n",
    "with tf.variable_scope('Encode'):\n",
    "    predictions = tf.identity(inputs_encoded, name='predictions') # <bc,hid> event embeddings.\n",
    "    \n",
    "with tf.variable_scope('Loss'):\n",
    "    sim_pos = tf.matrix_diag_part(tf.transpose(tf.tensordot(inputs_pos_encoded, \n",
    "                                                            tf.transpose(inputs_encoded, [1,0]), \n",
    "                                               axes=[[2],[0]]), [1,0,2]))\n",
    "        # op1. inputs_encoded -> <hid,bc>\n",
    "        # op2. dot: <bc,ctr,hid> * <hid,bc> -> <bc,ctr,bc>\n",
    "        # op3. transpose: <bc,ctr,bc> -> <ctr,bc,bc>\n",
    "        # op4. bc match: <ctr,bc>\n",
    "    sim_neg = tf.matrix_diag_part(tf.transpose(tf.tensordot(inputs_neg_encoded, \n",
    "                                                            tf.transpose(inputs_encoded, [1,0]), \n",
    "                                               axes=[[2],[0]]), [1,0,2])) \n",
    "    loss = tf.reduce_mean(tf.reduce_mean(tf.maximum(0., 1. + sim_neg - sim_pos), axis=0))\n",
    "        # op1. max(0, m + sim_neg - sim_pos), <ctr,bc>\n",
    "        # op2. average loss over contra instances: <bc,>\n",
    "        # op3. average loss over batch  \n",
    "        \n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "optimizer = tf.train.AdamOptimizer(LEARNING_RATE)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step, name='train_op')\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "TRAIN_SIZE = 10\n",
    "VERBOSE = 1\n",
    "# TRAIN_SIZE = len(FILE_NAMES)\n",
    "# VERBOSE = 10\n",
    "\n",
    "try:\n",
    "    loss_track = []\n",
    "    for e in range(NUM_EPOCHS):\n",
    "        print('Epoch ', e+1)\n",
    "        print('\\n')\n",
    "        curr_loss_track = []\n",
    "        file_indices = np.random.choice(list(range(len(FILE_NAMES))), size=TRAIN_SIZE, replace=False)\n",
    "        random.shuffle(file_indices)\n",
    "        curr_loss_track, curr_accuracy_track = [], []\n",
    "        for file_idx in file_indices:\n",
    "            edoc_a, edoc_b, _ = dill.load(open(nyt_code_dir+FILE_NAMES[file_idx],'rb')) # context not added\n",
    "            batch_x, batch_pos, batch_neg = get_batch(edoc_a, edoc_b)\n",
    "            fd = {inputs:batch_x, inputs_pos:batch_pos, inputs_neg:batch_neg}\n",
    "            _, step, loss_ = sess.run([train_op, global_step, loss], feed_dict=fd)\n",
    "            curr_loss_track.append(loss_)\n",
    "            if step%VERBOSE==0:\n",
    "                print(' average batch loss at step {}: <{}>'.format(step, np.mean(curr_loss_track)))\n",
    "        print('\\n')\n",
    "        print('  epoch mean loss: <{}>'.format(np.mean(curr_loss_track)))\n",
    "        print('\\n') \n",
    "        loss_track += curr_loss_track  \n",
    "except KeyboardInterrupt:\n",
    "    print('Stopped!')                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_files(target_dir):\n",
    "    for filename in os.listdir(target_dir):\n",
    "        os.remove(os.path.abspath(os.path.join(target_dir, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/04233/sw33286/AIDA-INDIV-MODEL-SAVE/our-model-ffnn-pretrain-sample/our-model-ffnn-pretrain-sample-00'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = \"/work/04233/sw33286/AIDA-INDIV-MODEL-SAVE/our-model-ffnn-pretrain-sample/\"\n",
    "save_path = save_dir + \"our-model-ffnn-pretrain-sample-00\"\n",
    "remove_all_files(save_dir)\n",
    "saver.save(sess, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "class BasicFeedForward:\n",
    "    # basic:\n",
    "    #   - not l2-regularized or dropout-regularized.\n",
    "    #   - dot Ã  la place de cosine.\n",
    "    \n",
    "    def __init__(self, rf_dir, rf_filename):\n",
    "        self.sess = tf.Session()\n",
    "        saver = tf.train.import_meta_graph(rf_dir + rf_filename)\n",
    "        saver.restore(self.sess, tf.train.latest_checkpoint(rf_dir))\n",
    "        self.graph = tf.get_default_graph()\n",
    "        self.inputs = self.graph.get_tensor_by_name('inputs:0') # <bc,nw-in-event=5>\n",
    "        self.predictions = self.graph.get_tensor_by_name('Encode/predictions:0') # <bc,hid>\n",
    "            # hid=100 hard coded for now.\n",
    "    \n",
    "    def embed_batch(self, batch_events):\n",
    "        return self.sess.run(self.predictions, feed_dict={self.inputs:batch_events})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_dir = \"/work/04233/sw33286/AIDA-INDIV-MODEL-SAVE/our-model-ffnn-pretrain-sample/\"\n",
    "restore_filename = \"our-model-ffnn-pretrain-sample-00.meta\"\n",
    "ffnn = BasicFeedForward(restore_dir, restore_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input event batch shape: 32 x 5\n",
      "Output event batch shape: 32 x 100\n"
     ]
    }
   ],
   "source": [
    "# Example: batch shapes\n",
    "\n",
    "edoc_a, edoc_b, _ = dill.load(open(nyt_code_dir+FILE_NAMES[0],'rb'))\n",
    "a,_,_ = get_batch(edoc_a, edoc_b) # only want <bc,nw-in-event=5> output\n",
    "print(\"Input event batch shape: {} x {}\".format(*a.shape))\n",
    "b = ffnn.embed_batch(a)\n",
    "print(\"Output event batch shape: {} x {}\".format(*b.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
