{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/work/04233/sw33286/AIDA-SCRIPTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn import LSTMCell, MultiRNNCell, DropoutWrapper\n",
    "\n",
    "from helpers import Indexer, batch\n",
    "from itertools import chain, product\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link to NYT data folder\n",
    "\n",
    "nyt_code_dir = \"/work/04233/sw33286/AIDA-DATA/nyt_end_salads_event_code_ffnn_embeddings/\"\n",
    "FILE_NAMES = os.listdir(nyt_code_dir)\n",
    "\n",
    "# Link to dictionary information\n",
    "\n",
    "# info_path = \"/work/04233/sw33286/AIDA-DATA/nyt_eng_salads_info/indexer_word2emb_100k_event.p\"\n",
    "# indexer100k, word2emb100k = dill.load(open(info_path, 'rb'))\n",
    "# glove_embs = []\n",
    "# for i in range(len(indexer100k)):\n",
    "#     glove_embs.append(word2emb100k[indexer100k.get_object(i)])\n",
    "# glove_embs = np.array(glove_embs)\n",
    "# print(glove_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EVENTS = 5\n",
    "EMB_SIZE = 100\n",
    "CTX_LEN = 20\n",
    "CTX_DUMMY = np.zeros([NUM_EVENTS, EMB_SIZE])\n",
    "\n",
    "def sample_two(lbs):\n",
    "    idx1, idx2 = np.random.choice(np.arange(len(lbs)), size=2, replace=False)\n",
    "    return idx1, idx2, 1 if lbs[idx1]==lbs[idx2] else 0\n",
    "\n",
    "def get_batch(file_idx):\n",
    "    filename = FILE_NAMES[file_idx]\n",
    "    batch_mix, batch_lbs = dill.load(open(nyt_code_dir+FILE_NAMES[file_idx],'rb'))\n",
    "    batch_x1, batch_x2, batch_y = [], [], []\n",
    "    for _ in range(BATCH_SIZE):\n",
    "        idx1, idx2, lb = sample_two(batch_lbs)\n",
    "        batch_x1.append(batch_mix[idx1])\n",
    "        batch_x2.append(batch_mix[idx2])\n",
    "        batch_y.append(lb)\n",
    "    size_ctx = len(batch_mix)\n",
    "    batch_ctx = batch_mix[:CTX_LEN] if size_ctx>=CTX_LEN else np.vstack((batch_mix,[CTX_DUMMY]*(CTX_LEN-size_ctx)))\n",
    "    return np.array(batch_x1), np.array(batch_x2), np.array(batch_ctx), np.array(batch_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 5, 100) (32, 5, 100) (20, 5, 100) (32,)\n",
      "(5, 100)\n"
     ]
    }
   ],
   "source": [
    "a1,a2,b,c = get_batch(0)\n",
    "print(a1.shape, a2.shape, b.shape, c.shape)\n",
    "print(CTX_DUMMY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTM-bilinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# EMB_SIZE = 100 # the hard coded event embedding size. # SPECIFIED ABOVE (PRETRAINED SIZE)\n",
    "HID_SIZE = 100 # let event embs be of the same hid-size as role-factored arg vectors.\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "KEEP_PROB = 0.7\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "# hyperparams for cnn context reader.\n",
    "FILTER_SIZES = [3,4,5]\n",
    "NUM_FILTERS = 50\n",
    "NUM_CHANNELS = 1\n",
    "\n",
    "input_x1 = tf.placeholder(tf.float32, [BATCH_SIZE, NUM_EVENTS, EMB_SIZE], name='input_x1')\n",
    "    # NB: this is embedded input by role-factored net.\n",
    "input_x2 = tf.placeholder(tf.float32, [BATCH_SIZE, NUM_EVENTS, EMB_SIZE], name='input_x2')\n",
    "input_ctx = tf.placeholder(tf.float32, [CTX_LEN, NUM_EVENTS, EMB_SIZE], name='input_ctx')\n",
    "input_y = tf.placeholder(tf.int32, [BATCH_SIZE], name='input_y')\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "input_x1_ffnn = tf.transpose(input_x1, [1,0,2]) # <mt=ne,bc,emb>\n",
    "input_x2_ffnn = tf.transpose(input_x2, [1,0,2])\n",
    "input_ctx_ffnn = tf.expand_dims(tf.expand_dims(tf.reshape(input_ctx, [CTX_LEN, NUM_EVENTS*EMB_SIZE]),0),-1)\n",
    "    # op1. reshape: <ctx,ne*emb>\n",
    "    # op2,3. expand dim for bc=1, chn=1: <bc=1,height=ctx,width=ne*emb,chn=1>\n",
    "\n",
    "cell = MultiRNNCell([DropoutWrapper(LSTMCell(HID_SIZE),output_keep_prob=keep_prob)]*NUM_LAYERS)\n",
    "\n",
    "def run_lstm(inputs): # inputs: <mt,bc,emb>\n",
    "    ((fw_outputs,bw_outputs), # <max-time=ne,bc,hid>, attention later if needed.\n",
    "     (fw_final_state,bw_final_state)) = ( # <bc,hid>\n",
    "        tf.nn.bidirectional_dynamic_rnn(cell_fw=cell,\n",
    "                                        cell_bw=cell,\n",
    "                                        inputs=inputs,\n",
    "                                        sequence_length=[NUM_EVENTS]*BATCH_SIZE,\n",
    "                                        dtype=tf.float32, time_major=True)\n",
    "    )    \n",
    "    return tf.concat([tf.concat([fw_state_tuple.h,bw_state_tuple.h], 1) # lstm-out size *= NUM_LAYERS by stacking.\n",
    "                      for fw_state_tuple,bw_state_tuple in zip(fw_final_state,bw_final_state)], 1), \\\n",
    "           tf.transpose(tf.concat([fw_outputs,bw_outputs], 2), [1,0,2])\n",
    "        # out1: <bc,hid*2*num-layers>\n",
    "        # out2: concat -> <ne,bc,hid*2> -> <bc,ne,hid*2>\n",
    "        \n",
    "with tf.variable_scope('BiLSTM') as scope: \n",
    "    final_state_x1, outputs_x1 = run_lstm(input_x1_ffnn)\n",
    "        # fs_x1: <bc,hid*2*num-layers>\n",
    "        # out_x1: <bc,ne,hid*2>\n",
    "    scope.reuse_variables()\n",
    "    final_state_x2, outputs_x2 = run_lstm(input_x2_ffnn)\n",
    "    \n",
    "def run_attention(outputs, state):\n",
    "    W_d = tf.get_variable('W_d', [HID_SIZE*2, HID_SIZE*2], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    W_s = tf.get_variable('W_s', [HID_SIZE*2*NUM_LAYERS, HID_SIZE*2], \n",
    "                          initializer=tf.contrib.layers.xavier_initializer())\n",
    "    d_W = tf.tensordot(outputs, W_d, axes=[[2],[0]])\n",
    "        # <bc,ne,hid*2> * <hid*2,hid*2> = <bc,ne,hid*2>\n",
    "    s_W = tf.expand_dims(tf.matmul(state, W_s), axis=1)\n",
    "        # op1. <bc,hid*2*num-layers> * <hid*2*num-layers,hid*2> -> <bc,hid*2>\n",
    "        # op2. <bc,hid*2> -> <bc,1,hid*2>\n",
    "    a_tsr = tf.nn.tanh(tf.add(d_W, s_W))\n",
    "        # op1. <bc,ne,hid*2> + <bc,1,hid*2> -> <bc,ne,hid*2>\n",
    "        # op2. elem-wise nonlinearity.\n",
    "    W_a = tf.get_variable('W_a', [HID_SIZE*2, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    a_W = tf.nn.softmax(tf.tensordot(a_tsr, W_a, axes=[[2],[0]]), dim=1)\n",
    "        # op1. <bc,ne,hid*2> * <hid*2,1> -> <bc,ne,1>\n",
    "        # op2. softmax over max-time=ne.\n",
    "    d_a = tf.reduce_sum(tf.multiply(outputs, a_W), axis=1)\n",
    "        # op1. <bc,ne,hid*2> elem* <bc,ne,1> -> <bc,ne,hid*2>\n",
    "        # op2. sum over max-time=ne (weighted sum) -> <bc,hid*2>\n",
    "    return d_a  \n",
    "\n",
    "with tf.variable_scope('Mutual-Attention') as scope:\n",
    "    x1_to_x2_att = run_attention(outputs_x2, final_state_x1) # x1 attending to x2, <bc,hid*2>\n",
    "    scope.reuse_variables()\n",
    "    x2_to_x1_att = run_attention(outputs_x1, final_state_x2) # x2 attending to x1\n",
    "    \n",
    "def run_cnn(inputs): # in: <bc=1,height=ctx,width=ne*emb,chn=1>\n",
    "    pool_outputs = []\n",
    "    for i,filter_size in enumerate(FILTER_SIZES):\n",
    "        with tf.variable_scope('CNN-ctx-%s' % filter_size):\n",
    "            filter_shape = [filter_size, NUM_EVENTS*EMB_SIZE, NUM_CHANNELS, NUM_FILTERS]\n",
    "            W = tf.get_variable('W', filter_shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.get_variable('b', [NUM_FILTERS], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            conv = tf.nn.conv2d(inputs, W, strides=[1,1,1,1], padding='VALID', name='conv')\n",
    "            h = tf.nn.relu(tf.nn.bias_add(conv, b), name='relu')\n",
    "            pool = tf.nn.max_pool(h, ksize=[1,CTX_LEN-filter_size+1,1,1], strides=[1,1,1,1], padding='VALID', name='pool')\n",
    "            pool_outputs.append(pool)\n",
    "    num_filters_total = NUM_FILTERS * len(FILTER_SIZES)\n",
    "    h_pool_flat = tf.nn.dropout(tf.reshape(tf.concat(pool_outputs, 3), [-1, num_filters_total]), keep_prob)\n",
    "    return h_pool_flat # <bc=1,num-filters*len(filter-sizes)>\n",
    "\n",
    "with tf.variable_scope('Context-reader') as scope:\n",
    "    ctx = tf.tile(run_cnn(input_ctx_ffnn), [BATCH_SIZE,1])\n",
    "        # op1. run-cnn out: <bc=1,num-filters*len(filter-sizes)>\n",
    "        # op2. create bc copies of it: <bc,num-filters*len(filter-sizes)>\n",
    "        \n",
    "def run_scores(fs_x1, fs_x2, att_12, att_21, c):\n",
    "    fv_size = HID_SIZE*2*NUM_LAYERS+HID_SIZE*2+NUM_FILTERS*len(FILTER_SIZES) \n",
    "        # sent encoding size + mutual attention size + context size.\n",
    "        # e.g. hid-size=100, num-filters=50\n",
    "        #      400 + 200 + 150 = 750\n",
    "    W_bi = tf.get_variable('W_bi', [fv_size, fv_size], \n",
    "                           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    fv_x1 = tf.concat([fs_x1,att_12,c],axis=1) \n",
    "        # concat: [<bc,hid*2*num-layers>, <bc,hid*2>, <bc,num-filters*len(filter-sizes)>]\n",
    "        #   -> <bc,fv = hid*2*num-layers + hid*2 + num-filters*len(filter-sizes)>\n",
    "    fv_x2 = tf.concat([fs_x2,att_21,c],axis=1)\n",
    "    return tf.nn.sigmoid(tf.diag_part(tf.matmul(tf.matmul(fv_x1,W_bi),tf.transpose(fv_x2))),name='scores')\n",
    "        # op1. bilinear mult: <bc,fv> * <fv,fv> * <fv,bc> -> <bc,bc>\n",
    "        # op2: match bc: <bc,>\n",
    "        # op3: sigmoid to compute scores: <bc,>\n",
    "        \n",
    "scores = run_scores(final_state_x1, final_state_x2, x1_to_x2_att, x2_to_x1_att, ctx)\n",
    "predictions = tf.cast(tf.round(scores), tf.int32, name='predictions')     \n",
    "    \n",
    "with tf.name_scope('Loss'):\n",
    "    losses = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(input_y, tf.float32), logits=scores)\n",
    "    loss = tf.reduce_mean(losses, name='loss')\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "    correct_predictions = tf.equal(predictions, input_y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32), name='accuracy')\n",
    "    \n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "optimizer = tf.train.AdamOptimizer(LEARNING_RATE)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step, name='train_op')\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "save_dir = \"/work/04233/sw33286/AIDA-INDIV-MODEL-SAVE-EVENT/our-model-ffnn-init-bilstm/\"\n",
    "save_path = save_dir + \"our-model-ffnn-init-bilstm-00\"\n",
    "\n",
    "def remove_all_files(target_dir):\n",
    "    for filename in os.listdir(target_dir):\n",
    "        os.remove(os.path.abspath(os.path.join(target_dir, filename)))\n",
    "        \n",
    "def checkpoint_model(s_dir, s_path, svr, ss):\n",
    "    # save_dir, save_path, saver, sess\n",
    "    remove_all_files(s_dir)\n",
    "    svr.save(ss, s_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "TRAIN_SIZE = 10\n",
    "VERBOSE = 1\n",
    "SAVE_PER = 50000\n",
    "# TRAIN_SIZE = len(FILE_NAMES)\n",
    "# VERBOSE = 1000\n",
    "\n",
    "loss_track, accuracy_track = [], []\n",
    "try:\n",
    "    for e in range(NUM_EPOCHS):\n",
    "        print('Epoch ', e+1)\n",
    "        print('\\n')\n",
    "        file_indices = np.random.choice(list(range(len(FILE_NAMES))), size=TRAIN_SIZE, replace=False)\n",
    "        random.shuffle(file_indices)\n",
    "        curr_loss_track, curr_accuracy_track = [], []\n",
    "        for file_idx in file_indices:\n",
    "            batch_x1, batch_x2, batch_ctx, batch_y = get_batch(file_idx)\n",
    "            fd = {input_x1:batch_x1, input_x2:batch_x2,\n",
    "                  input_ctx:batch_ctx,\n",
    "                  input_y:batch_y,\n",
    "                  keep_prob:KEEP_PROB}\n",
    "            _, step, loss_, accuracy_ = sess.run([train_op, global_step, loss, accuracy], feed_dict=fd)\n",
    "            curr_loss_track.append(loss_)\n",
    "            curr_accuracy_track.append(accuracy_)\n",
    "            if step%VERBOSE==0:\n",
    "                print(' average batch loss & accuracy at step {}: <{}, {}>'.format(step,\n",
    "                                                                                   np.mean(curr_loss_track), \n",
    "                                                                                   np.mean(curr_accuracy_track)))\n",
    "            if step%SAVE_PER==0:\n",
    "                checkpoint_model(save_dir, save_path, saver, sess)\n",
    "                print(' [SAVE] model checkpointed at step {}'.format(step))\n",
    "    print('\\n')\n",
    "    print('  epoch mean loss & accuracy: <{}, {}>'.format(np.mean(curr_loss_track),np.mean(curr_accuracy_track)))\n",
    "    print('\\n') \n",
    "    loss_track += curr_loss_track\n",
    "    accuracy_track += curr_accuracy_track\n",
    "except KeyboardInterrupt:\n",
    "    print('Stopped!')            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_model(save_dir, save_path, saver, sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model continued training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/work/04233/sw33286/AIDA-SCRIPTS\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn import LSTMCell, MultiRNNCell, DropoutWrapper\n",
    "\n",
    "from helpers import Indexer, batch\n",
    "from itertools import chain, product\n",
    "from collections import defaultdict\n",
    "\n",
    "# Link to NYT data folder\n",
    "\n",
    "nyt_code_dir = \"/work/04233/sw33286/AIDA-DATA/nyt_end_salads_event_code_ffnn_embeddings/\"\n",
    "FILE_NAMES = os.listdir(nyt_code_dir)\n",
    "\n",
    "# # Link to dictionary information\n",
    "\n",
    "# info_path = \"/work/04233/sw33286/AIDA-DATA/nyt_eng_salads_info/indexer_word2emb_100k_event.p\"\n",
    "# indexer100k, word2emb100k = dill.load(open(info_path, 'rb'))\n",
    "# glove_embs = []\n",
    "# for i in range(len(indexer100k)):\n",
    "#     glove_embs.append(word2emb100k[indexer100k.get_object(i)])\n",
    "# glove_embs = np.array(glove_embs)\n",
    "# print(glove_embs.shape)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EVENTS = 5\n",
    "EMB_SIZE = 100\n",
    "CTX_LEN = 20\n",
    "CTX_DUMMY = np.zeros([NUM_EVENTS, EMB_SIZE])\n",
    "\n",
    "def sample_two(lbs):\n",
    "    idx1, idx2 = np.random.choice(np.arange(len(lbs)), size=2, replace=False)\n",
    "    return idx1, idx2, 1 if lbs[idx1]==lbs[idx2] else 0\n",
    "\n",
    "def get_batch(file_idx):\n",
    "    filename = FILE_NAMES[file_idx]\n",
    "    batch_mix, batch_lbs = dill.load(open(nyt_code_dir+FILE_NAMES[file_idx],'rb'))\n",
    "    batch_x1, batch_x2, batch_y = [], [], []\n",
    "    for _ in range(BATCH_SIZE):\n",
    "        idx1, idx2, lb = sample_two(batch_lbs)\n",
    "        batch_x1.append(batch_mix[idx1])\n",
    "        batch_x2.append(batch_mix[idx2])\n",
    "        batch_y.append(lb)\n",
    "    size_ctx = len(batch_mix)\n",
    "    batch_ctx = batch_mix[:CTX_LEN] if size_ctx>=CTX_LEN else np.vstack((batch_mix,[CTX_DUMMY]*(CTX_LEN-size_ctx)))\n",
    "    return np.array(batch_x1), np.array(batch_x2), np.array(batch_ctx), np.array(batch_y) \n",
    "        # batch_x*: <bc,ne,emb>, batch_ctx: <ctx,ne,emb>, batch_y: <bc,>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_dir = \"/work/04233/sw33286/AIDA-INDIV-MODEL-SAVE-EVENT/our-model-ffnn-init-bilstm/\"\n",
    "restore_filename = \"our-model-ffnn-init-bilstm-00.meta\"\n",
    "\n",
    "sess = tf.Session()\n",
    "saver = tf.train.import_meta_graph(restore_dir + restore_filename)\n",
    "saver.restore(sess, tf.train.latest_checkpoint(restore_dir))\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "input_x1 = graph.get_tensor_by_name('input_x1:0')\n",
    "input_x2 = graph.get_tensor_by_name('input_x2:0')\n",
    "input_ctx = graph.get_tensor_by_name('input_ctx:0')\n",
    "input_y = graph.get_tensor_by_name('input_y:0')\n",
    "keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
    "\n",
    "scores = graph.get_tensor_by_name('scores:0')\n",
    "predictions = graph.get_tensor_by_name('predictions:0')\n",
    "loss = graph.get_tensor_by_name('Loss/loss:0')\n",
    "accuracy = graph.get_tensor_by_name('Accuracy/accuracy:0')\n",
    "global_step = graph.get_tensor_by_name('global_step:0')\n",
    "train_op = graph.get_tensor_by_name('train_op:0')\n",
    "\n",
    "save_dir = \"/work/04233/sw33286/AIDA-INDIV-MODEL-SAVE-EVENT/our-model-ffnn-init-bilstm/\"\n",
    "save_path = save_dir + \"our-model-ffnn-init-bilstm-00\"\n",
    "\n",
    "def remove_all_files(target_dir):\n",
    "    for filename in os.listdir(target_dir):\n",
    "        os.remove(os.path.abspath(os.path.join(target_dir, filename)))\n",
    "        \n",
    "def checkpoint_model(s_dir, s_path, svr, ss):\n",
    "    # save_dir, save_path, saver, sess\n",
    "    remove_all_files(s_dir)\n",
    "    svr.save(ss, s_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "TRAIN_SIZE = 10\n",
    "VERBOSE = 1\n",
    "SAVE_PER = 50000\n",
    "# TRAIN_SIZE = len(FILE_NAMES)\n",
    "# VERBOSE = 1000\n",
    "\n",
    "loss_track, accuracy_track = [], []\n",
    "try:\n",
    "    for e in range(NUM_EPOCHS):\n",
    "        print('Epoch ', e+1)\n",
    "        print('\\n')\n",
    "        file_indices = np.random.choice(list(range(len(FILE_NAMES))), size=TRAIN_SIZE, replace=False)\n",
    "        random.shuffle(file_indices)\n",
    "        curr_loss_track, curr_accuracy_track = [], []\n",
    "        for file_idx in file_indices:\n",
    "            batch_x1, batch_x2, batch_ctx, batch_y = get_batch(file_idx)\n",
    "            fd = {input_x1:batch_x1, input_x2:batch_x2,\n",
    "                  input_ctx:batch_ctx,\n",
    "                  input_y:batch_y,\n",
    "                  keep_prob:KEEP_PROB}\n",
    "            _, step, loss_, accuracy_ = sess.run([train_op, global_step, loss, accuracy], feed_dict=fd)\n",
    "            curr_loss_track.append(loss_)\n",
    "            curr_accuracy_track.append(accuracy_)\n",
    "            if step%VERBOSE==0:\n",
    "                print(' average batch loss & accuracy at step {}: <{}, {}>'.format(step,\n",
    "                                                                                   np.mean(curr_loss_track), \n",
    "                                                                                   np.mean(curr_accuracy_track)))\n",
    "            if step%SAVE_PER==0:\n",
    "                checkpoint_model(save_dir, save_path, saver, sess)\n",
    "                print(' [SAVE] model checkpointed at step {}'.format(step))\n",
    "    print('\\n')\n",
    "    print('  epoch mean loss & accuracy: <{}, {}>'.format(np.mean(curr_loss_track),np.mean(curr_accuracy_track)))\n",
    "    print('\\n') \n",
    "    loss_track += curr_loss_track\n",
    "    accuracy_track += curr_accuracy_track\n",
    "except KeyboardInterrupt:\n",
    "    print('Stopped!')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
