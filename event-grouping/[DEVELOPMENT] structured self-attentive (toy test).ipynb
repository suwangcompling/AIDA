{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-attentive sentence-pair classifier\n",
    "\n",
    "* Adapted from Lin et al. (2017) A Structured Self-attentive Sentence Embedding. ICLR17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/work/04233/sw33286/AIDA-SCRIPTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn import LSTMCell, MultiRNNCell, DropoutWrapper\n",
    "\n",
    "from helpers import Indexer, batch\n",
    "from itertools import chain, product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHARED_SIZE = 2 # size of noise (or, common vocab for all types).\n",
    "\n",
    "TYPES = ['ANIMAL','VEHICLE','NATURE','FURNITURE','FRUIT']\n",
    "SHARED_VOCAB = ['share'+str(i+1) for i in range(SHARED_SIZE)]\n",
    "TYPE2VOCAB = {'ANIMAL': ['cat','dog','pig','horse','deer']            + SHARED_VOCAB,\n",
    "              'VEHICLE': ['car','bike','motorcycle','train','bus']    + SHARED_VOCAB,\n",
    "              'NATURE': ['hill','mountain','lake','river','valley']   + SHARED_VOCAB,\n",
    "              'FURNITURE': ['stool','table','closet','cabinet','bed'] + SHARED_VOCAB,\n",
    "              'FRUIT': ['apple','pear','strawberry','grape','tomato'] + SHARED_VOCAB}\n",
    "VOCAB = list(chain.from_iterable(TYPE2VOCAB.values()))\n",
    "\n",
    "indexer = Indexer()\n",
    "indexer.get_index('PAD')\n",
    "for word in VOCAB:\n",
    "    indexer.get_index(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = 5\n",
    "NUM_EVENTS = 3\n",
    "DOC_LEN = 4\n",
    "\n",
    "def to_sent(code):\n",
    "    return [[indexer.get_object(idx) for idx in event] for event in code]\n",
    "\n",
    "def get_rand_event_code(sem_type):\n",
    "    return [indexer.get_index(np.random.choice(TYPE2VOCAB[sem_type])) for _ in range(NUM_WORDS)]\n",
    "\n",
    "def get_mixture(type1, type2):\n",
    "    doc_a = [[get_rand_event_code(type1) for _ in range(NUM_EVENTS)] for _ in range(DOC_LEN)]\n",
    "    doc_b = [[get_rand_event_code(type2) for _ in range(NUM_EVENTS)] for _ in range(DOC_LEN)]   \n",
    "    doc_mix = np.array(doc_a[:] + doc_b[:])\n",
    "    doc_lbs = np.array([0]*DOC_LEN + [1]*DOC_LEN)\n",
    "    indices = list(range(DOC_LEN*2))\n",
    "    random.shuffle(indices)\n",
    "    doc_mix = doc_mix[indices]\n",
    "    doc_lbs = doc_lbs[indices]\n",
    "    return doc_a, doc_b, doc_mix, doc_lbs    \n",
    "\n",
    "def batch_mixture(doc_a, doc_b, k):\n",
    "    batch_x1, batch_x2, batch_y = [], [], []\n",
    "    ys = [1,0,0,1]\n",
    "    for _ in range(k):\n",
    "        for i,(da,db) in enumerate(product([doc_a,doc_b],[doc_a,doc_b])):\n",
    "            batch_x1.append(random.choice(da))\n",
    "            batch_x2.append(random.choice(db))\n",
    "            batch_y.append(ys[i])\n",
    "    return np.array(batch_x1), np.array(batch_x2), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-attention with bi-linear final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "VOCAB_SIZE = len(indexer)\n",
    "EMB_SIZE = 20\n",
    "HID_SIZE = 10\n",
    "CHN_SIZE = 2 # channel size. #attention channels.\n",
    "KEEP_PROB = 0.7\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    \n",
    "    input_x1 = tf.placeholder(tf.int32, [5, 3], name='input_x1') # <max-time=nw,batch-size=ne>\n",
    "    input_x2 = tf.placeholder(tf.int32, [5, 3], name='input_x2')\n",
    "    input_x1_length = tf.placeholder(tf.int32, [3], name='input_x1_length')\n",
    "    input_x2_length = tf.placeholder(tf.int32, [3], name='input_x2_length')\n",
    "    input_y  = tf.placeholder(tf.int32, [1], name='input_y')\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "    with tf.variable_scope('Embeddings'):\n",
    "        embeddings = tf.get_variable('embeddings', [VOCAB_SIZE, EMB_SIZE], \n",
    "                                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "        input_x1_embedded = tf.nn.embedding_lookup(embeddings, input_x1) # <max-time, batch-size, emb-size>\n",
    "        input_x2_embedded = tf.nn.embedding_lookup(embeddings, input_x2)\n",
    "\n",
    "    cell = DropoutWrapper(LSTMCell(HID_SIZE),output_keep_prob=keep_prob)\n",
    "\n",
    "    def run_lstm(cell, inputs, inputs_length): # lstm-out size *= 2 by bidirectionality.\n",
    "        ((fw_outputs,bw_outputs), # <max-time, batch-size, hid-size>, attention later if needed.\n",
    "         (fw_final_state,bw_final_state)) = ( # <batch-size, hid-size>\n",
    "            tf.nn.bidirectional_dynamic_rnn(cell_fw=cell,\n",
    "                                            cell_bw=cell,\n",
    "                                            inputs=inputs,\n",
    "                                            sequence_length=inputs_length,\n",
    "                                            dtype=tf.float32, time_major=True)\n",
    "        )\n",
    "        return tf.concat([fw_outputs,bw_outputs], axis=2) # <max-time, batch-size, hid-size*2>\n",
    "\n",
    "    with tf.variable_scope('Bi-LSTM') as scope:\n",
    "        input_x1_hidden = tf.transpose(run_lstm(cell, input_x1_embedded, input_x1_length),[1,0,2]) \n",
    "            # op1. run_lstm output: <max-time, batch-size, hid-size*2>\n",
    "            # op2. transpose: <batch-size=ne, max-time=nw, hid-size*2=2u>, for self attending.\n",
    "        scope.reuse_variables()\n",
    "        input_x2_hidden = tf.transpose(run_lstm(cell, input_x2_embedded, input_x2_length),[1,0,2])\n",
    "\n",
    "    def run_self_attention(inputs): # inputs = <batch-size=ne, max-time=nw, hid-size*2=2u>\n",
    "        W_s1 = tf.get_variable('W_s1', [2*HID_SIZE, HID_SIZE], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            # shape = <hid-size*2=2u, hid-size>\n",
    "            # axis 1 doesn't have to be HID_SIZE, could be any d.\n",
    "        W_s2 = tf.get_variable('W_s2', [HID_SIZE, CHN_SIZE], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        inputs_s1 = tf.tensordot(inputs, W_s1, axes=[[2],[0]]) # <batch-size, max-time=nw, hid-size=d>\n",
    "        inputs_s2 = tf.tensordot(tf.nn.tanh(inputs_s1), W_s2, axes=[[2],[0]]) # <batch-size, max-time=nw, chn-size=r>\n",
    "        return tf.nn.softmax(tf.transpose(inputs_s2, [0,2,1]), dim=-1)\n",
    "            # op1. <batch-size, max-time=nw, chn-size=r> -> <batch-size, chn-size=r, max-time=nw>, for later attending.\n",
    "            # op2. softmax along the n dimension (attention over component words).\n",
    "\n",
    "    with tf.variable_scope('Self-attention') as scope:\n",
    "        att_x1 = run_self_attention(input_x1_hidden) # <batch-size, chn-size, max-time=nw>\n",
    "        scope.reuse_variables()\n",
    "        att_x2 = run_self_attention(input_x2_hidden)\n",
    "        # apply attention\n",
    "        input_x1_att = tf.matrix_diag_part(tf.transpose(tf.tensordot(tf.transpose(input_x1_hidden, [0,2,1]), att_x1, \n",
    "                                                                     axes=[[2],[2]]),\n",
    "                                                        [3,1,0,2]))\n",
    "            # op1. <batch-size=ne, max-time=nw, hid-size*2=2u> -> <batch-size=ne, hid-size*2=2u, max-time=nw>\n",
    "            # op2. result: <batch-size, hid-size*2=2u, batch-size, chn-size=r>\n",
    "            # op3. transpose to <chn-size=r, hid-size*2=2u, batch-size, batch-size>\n",
    "            # op4. match batch dim: take the diag part, get <chn-size=r, hid-size*2=2u, batch-size>\n",
    "        input_x2_att = tf.matrix_diag_part(tf.transpose(tf.tensordot(tf.transpose(input_x2_hidden, [0,2,1]), att_x2, \n",
    "                                                                     axes=[[2],[2]]),\n",
    "                                                        [3,1,0,2]))\n",
    "            # Lin et al. (2017) also applies diagonal penalty, but this doesn't seem to be terribly effective.\n",
    "            #   omitted here for now.\n",
    "        final_vec_x1 = tf.reshape(tf.transpose(input_x1_att, [2,0,1]), [1, -1])\n",
    "            # op1. transpose for computing loss: \n",
    "            #   <chn-size=r, hid-size*2=2u, batch-size> -> <batch-size, chn-size=r, hid-size*2=2u>\n",
    "            # op2. concat attended information from all events in all channels (batch-size x chn-size x hid-size*2)\n",
    "            #   <1, batch-sizechn-size*hid-size*2>\n",
    "        final_vec_x2 = tf.reshape(tf.transpose(input_x2_att, [2,0,1]), [1, -1])\n",
    "\n",
    "    with tf.variable_scope('Scores'):\n",
    "        final_vec_size = NUM_EVENTS*HID_SIZE*2*CHN_SIZE \n",
    "            # multi-events = *num-events, bidirectional=*2, multi-channel attetion = *num-channels.\n",
    "        W_bi = tf.get_variable('W_bi', [final_vec_size, final_vec_size], \n",
    "                               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        scores = tf.nn.sigmoid(tf.diag_part(tf.matmul(tf.matmul(final_vec_x1,W_bi),tf.transpose(final_vec_x2))),name='scores')\n",
    "        predictions = tf.cast(tf.round(scores), tf.int32, name='predictions') \n",
    "\n",
    "    with tf.name_scope('Loss'):\n",
    "        losses = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(input_y, tf.float32), logits=scores)\n",
    "        loss = tf.reduce_mean(losses, name='loss')\n",
    "\n",
    "    with tf.name_scope('Accuracy'):\n",
    "        correct_predictions = tf.equal(predictions, input_y)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32), name='accuracy')\n",
    "\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    optimizer = tf.train.AdamOptimizer(LEARNING_RATE)\n",
    "    grads_and_vars = optimizer.compute_gradients(loss)\n",
    "    train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step, name='train_op')\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1\n",
      "\n",
      "\n",
      " average batch loss & accuracy at step 1000: <0.7224329710006714, 0.640999972820282>\n",
      " average batch loss & accuracy at step 2000: <0.7026016712188721, 0.7260000109672546>\n",
      " average batch loss & accuracy at step 3000: <0.6781991720199585, 0.7570000290870667>\n",
      " average batch loss & accuracy at step 4000: <0.6669455170631409, 0.765250027179718>\n",
      " average batch loss & accuracy at step 5000: <0.6612539291381836, 0.7648000121116638>\n",
      " average batch loss & accuracy at step 6000: <0.6513721346855164, 0.7821666598320007>\n",
      " average batch loss & accuracy at step 7000: <0.6416612863540649, 0.7965714335441589>\n",
      " average batch loss & accuracy at step 8000: <0.6319300532341003, 0.8106250166893005>\n",
      " average batch loss & accuracy at step 9000: <0.6259729862213135, 0.8183333277702332>\n",
      " average batch loss & accuracy at step 10000: <0.6202099323272705, 0.8260999917984009>\n",
      " average batch loss & accuracy at step 11000: <0.6164026260375977, 0.8309999704360962>\n",
      " average batch loss & accuracy at step 12000: <0.6123799681663513, 0.8364166617393494>\n",
      " average batch loss & accuracy at step 13000: <0.609154462814331, 0.8406922817230225>\n",
      " average batch loss & accuracy at step 14000: <0.6081575155258179, 0.8414999842643738>\n",
      " average batch loss & accuracy at step 15000: <0.603809118270874, 0.8478000164031982>\n",
      " average batch loss & accuracy at step 16000: <0.6021740436553955, 0.8498125076293945>\n",
      "\n",
      "\n",
      "  epoch mean loss & accuracy: <0.6021740436553955, 0.8498125076293945>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 1\n",
    "NUM_BATCHES = 1000\n",
    "VERBOSE = 1000\n",
    "\n",
    "loss_track, accuracy_track = [], []\n",
    "for e in range(NUM_EPOCHS):\n",
    "    print('Epoch ', e+1)\n",
    "    print('\\n')\n",
    "    curr_loss_track, curr_accuracy_track = [], []\n",
    "    for _ in range(NUM_BATCHES):\n",
    "        type1, type2 = np.random.choice(TYPES, 2, replace=False)\n",
    "        doc_a, doc_b, _, _ = get_mixture(type1, type2)\n",
    "        batch_x1, batch_x2, batch_y = batch_mixture(doc_a, doc_b, k=4)\n",
    "        for x1,x2,y in zip(batch_x1,batch_x2,batch_y):\n",
    "            x1,x1_len = batch(x1)\n",
    "            x2,x2_len = batch(x2)\n",
    "            fd = {input_x1:x1, input_x1_length:x1_len,\n",
    "                  input_x2:x2, input_x2_length:x2_len,\n",
    "                  input_y:[y],\n",
    "                  keep_prob:KEEP_PROB}\n",
    "            _, step, loss_, accuracy_ = sess.run([train_op, global_step, loss, accuracy], feed_dict=fd)\n",
    "            curr_loss_track.append(loss_)\n",
    "            curr_accuracy_track.append(accuracy_)\n",
    "            if step%VERBOSE==0:\n",
    "                print(' average batch loss & accuracy at step {}: <{}, {}>'.format(step, np.mean(curr_loss_track), \n",
    "                                                                                         np.mean(curr_accuracy_track)))\n",
    "    print('\\n')\n",
    "    print('  epoch mean loss & accuracy: <{}, {}>'.format(np.mean(curr_loss_track),np.mean(curr_accuracy_track)))\n",
    "    print('\\n') \n",
    "    loss_track += curr_loss_track\n",
    "    accuracy_track += curr_accuracy_track"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
