{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/work/04233/sw33286/AIDA-SCRIPTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn import LSTMCell, MultiRNNCell, DropoutWrapper\n",
    "\n",
    "from helpers import Indexer, batch\n",
    "from itertools import chain, product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHARED_SIZE = 2 # size of noise (or, common vocab for all types).\n",
    "\n",
    "TYPES = ['ANIMAL','VEHICLE','NATURE','FURNITURE','FRUIT']\n",
    "SHARED_VOCAB = ['share'+str(i+1) for i in range(SHARED_SIZE)]\n",
    "TYPE2VOCAB = {'ANIMAL': ['cat','dog','pig','horse','deer']            + SHARED_VOCAB,\n",
    "              'VEHICLE': ['car','bike','motorcycle','train','bus']    + SHARED_VOCAB,\n",
    "              'NATURE': ['hill','mountain','lake','river','valley']   + SHARED_VOCAB,\n",
    "              'FURNITURE': ['stool','table','closet','cabinet','bed'] + SHARED_VOCAB,\n",
    "              'FRUIT': ['apple','pear','strawberry','grape','tomato'] + SHARED_VOCAB}\n",
    "VOCAB = list(chain.from_iterable(TYPE2VOCAB.values()))\n",
    "\n",
    "indexer = Indexer()\n",
    "indexer.get_index('PAD')\n",
    "for word in VOCAB:\n",
    "    indexer.get_index(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_LEN = 5\n",
    "SENT_FROM_LEN = 5\n",
    "SENT_TO_LEN = 15\n",
    "CTX_LEN = ((SENT_TO_LEN-SENT_FROM_LEN)//2)*DOC_LEN\n",
    "\n",
    "def to_sent(code):\n",
    "    return [indexer.get_object(idx) for idx in code]\n",
    "\n",
    "def get_rand_sent_code(sem_type, sent_len):\n",
    "    return [indexer.get_index(np.random.choice(TYPE2VOCAB[sem_type])) for _ in range(sent_len)]\n",
    "\n",
    "def get_mixture(type1, type2):\n",
    "    doc_a = [get_rand_sent_code(type1, np.random.randint(SENT_FROM_LEN, SENT_TO_LEN)) for _ in range(DOC_LEN)]\n",
    "    doc_b = [get_rand_sent_code(type2, np.random.randint(SENT_FROM_LEN, SENT_TO_LEN)) for _ in range(DOC_LEN)]\n",
    "    doc_mix = np.array(doc_a[:] + doc_b[:])\n",
    "    doc_lbs = np.array([0]*DOC_LEN + [1]*DOC_LEN)\n",
    "    indices = list(range(DOC_LEN*2))\n",
    "    random.shuffle(indices)\n",
    "    doc_mix = doc_mix[indices]\n",
    "    doc_lbs = doc_lbs[indices]\n",
    "    return doc_a, doc_b, doc_mix, doc_lbs\n",
    "    \n",
    "# def batch_mixture(doc_a, doc_b, doc_mix, k):\n",
    "#     batch_x1, batch_x2, batch_ctx, batch_y = [], [], [], []\n",
    "#     ys = [1,0,0,1]\n",
    "#     doc_mix_flat = list(chain.from_iterable(doc_mix))\n",
    "#     doc_mix_len = len(doc_mix_flat)\n",
    "#     doc_mix_padded = np.array(doc_mix_flat[:CTX_LEN]) if doc_mix_len>=CTX_LEN else np.array(doc_mix_flat+[0]*(CTX_LEN-doc_mix_len))\n",
    "#     for _ in range(k):\n",
    "#         for i,(da,db) in enumerate(product([doc_a,doc_b],[doc_a,doc_b])):\n",
    "#             batch_x1.append(random.choice(da))\n",
    "#             batch_x2.append(random.choice(db))\n",
    "#             batch_y.append(ys[i])\n",
    "#     return batch(batch_x1), batch(batch_x2), batch([doc_mix_padded]), np.array(batch_y)\n",
    "\n",
    "# def get_batch(n=40):\n",
    "#     if n%4!=0:\n",
    "#         raise ValueError('The current generation scheme only supports multiples of 4 for batch size!')\n",
    "#     type1, type2 = np.random.choice(TYPES, 2, replace=False)\n",
    "#     doc_a, doc_b, doc_mix, _ = get_mixture(type1, type2) # document labels isn't germane here.\n",
    "#     (batch_x1,batch_x1_len), (batch_x2,batch_x2_len), (batch_ctx,batch_ctx_len), batch_y = \\\n",
    "#                                                                 batch_mixture(doc_a,doc_b,doc_mix,n//4)\n",
    "#     return batch_x1,batch_x1_len,batch_x2,batch_x2_len,batch_ctx,batch_ctx_len,batch_y\n",
    "\n",
    "def batch_mixture(doc_a, doc_b, k):\n",
    "    batch_x1, batch_x2, batch_y = [], [], []\n",
    "    ys = [1,0,0,1]\n",
    "    for _ in range(k):\n",
    "        for i,(da,db) in enumerate(product([doc_a,doc_b],[doc_a,doc_b])):\n",
    "            batch_x1.append(random.choice(da))\n",
    "            batch_x2.append(random.choice(db))\n",
    "            batch_y.append(ys[i])\n",
    "    return batch_x1, batch_x2, batch_y\n",
    "\n",
    "def get_batch(n=40):\n",
    "    if n%4!=0:\n",
    "        raise ValueError('The current generation scheme only supports multiples of 4 for batch size!')\n",
    "    type1, type2 = np.random.choice(TYPES, 2, replace=False)\n",
    "    doc_a, doc_b, doc_mix, _ = get_mixture(type1, type2) # document labels isn't germane here.\n",
    "    batch_x1, batch_x2, batch_y = batch_mixture(doc_a,doc_b,n//4)\n",
    "    return batch_x1, batch_x2, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "VOCAB_SIZE = len(indexer)\n",
    "EMB_SIZE = 20\n",
    "HID_SIZE = 10\n",
    "NUM_LAYERS = 2\n",
    "KEEP_PROB = 0.7\n",
    "\n",
    "input_x1 = tf.placeholder(tf.int32, [None, 1], name='input_x1') # <max-time, batch-size>\n",
    "input_x2 = tf.placeholder(tf.int32, [None, 1], name='input_x2')\n",
    "input_x1_length = tf.placeholder(tf.int32, [1], name='input_x1_length')\n",
    "input_x2_length = tf.placeholder(tf.int32, [1], name='input_x2_length')\n",
    "input_y  = tf.placeholder(tf.int32, [1], name='input_y')\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "with tf.variable_scope('Embeddings'):\n",
    "    embeddings = tf.get_variable('embeddings', [VOCAB_SIZE, EMB_SIZE], \n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "    input_x1_embedded = tf.nn.embedding_lookup(embeddings, input_x1) # <max-time, batch-size, emb-size>\n",
    "    input_x2_embedded = tf.nn.embedding_lookup(embeddings, input_x2)\n",
    "    \n",
    "cell = DropoutWrapper(LSTMCell(HID_SIZE),output_keep_prob=keep_prob)\n",
    "    \n",
    "def run_sent_lstm(cell, inputs, inputs_length):\n",
    "    ((fw_outputs,bw_outputs), # <max-time, batch-size, hid-size>, attention later if needed.\n",
    "     (fw_final_state,bw_final_state)) = ( # <batch-size, hid-size>\n",
    "        tf.nn.bidirectional_dynamic_rnn(cell_fw=cell,\n",
    "                                        cell_bw=cell,\n",
    "                                        inputs=inputs,\n",
    "                                        sequence_length=inputs_length,\n",
    "                                        dtype=tf.float32, time_major=True)\n",
    "    )\n",
    "    return tf.concat([fw_final_state.h,bw_final_state.h], 1), \\\n",
    "           tf.squeeze(tf.concat([fw_outputs,bw_outputs], 2), 1)\n",
    "        # op1: <batch-size, hid-size*2>\n",
    "        # op2: <max-time, batch-size, hid-size*2> -> <max-time, hid-size*2>\n",
    "        # NB: batch-size = 1 here.\n",
    "\n",
    "with tf.variable_scope('Bi-LSTM') as scope:\n",
    "    final_state_x1, outputs_x1 = run_sent_lstm(cell, input_x1_embedded, input_x1_length)\n",
    "    scope.reuse_variables() # both sentence inputs share the same weights.\n",
    "    final_state_x2, outputs_x2 = run_sent_lstm(cell, input_x2_embedded, input_x2_length)\n",
    "\n",
    "def run_attention(d_mat, s_vec):\n",
    "    W_d = tf.get_variable('W_d', [HID_SIZE*2, HID_SIZE*2], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    W_s = tf.get_variable('W_s', [HID_SIZE*2, HID_SIZE*2], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    d_W = tf.matmul(d_mat, W_d) # <max-time,20> * <20,20> = <max-time,20>\n",
    "    s_W = tf.squeeze(tf.matmul(s_vec, W_s), 0) # <1,20> * <20,20> = <1,20> -> <20,>\n",
    "    a_mat = tf.nn.tanh(tf.add(d_W, s_W)) # <max-time,20>\n",
    "    W_a = tf.get_variable('W_a', [HID_SIZE*2, 1], initializer=tf.contrib.layers.xavier_initializer()) # <20,1>\n",
    "    a_W = tf.transpose(tf.matmul(a_mat, W_a), [1,0]) # <1,max-time>\n",
    "    d_a = tf.matmul(a_W, d_mat) # <1,20>\n",
    "    return d_a\n",
    "\n",
    "with tf.variable_scope('Mutual-Attention') as scope:\n",
    "    x1_to_x2_attvec = run_attention(outputs_x2, final_state_x1) # x1 attending to x2\n",
    "    scope.reuse_variables()\n",
    "    x2_to_x1_attvec = run_attention(outputs_x1, final_state_x2) # x2 attending to x1\n",
    "    \n",
    "def run_scores(fs_x1, fs_x2, av_12, av_21):\n",
    "    W_bi = tf.get_variable('W_bi', [HID_SIZE*4, HID_SIZE*4], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    fv_x1 = tf.concat([fs_x1,av_12],axis=1) # <1,40>\n",
    "    fv_x2 = tf.concat([fs_x2,av_21],axis=1)\n",
    "    return tf.nn.sigmoid(tf.diag_part(tf.matmul(tf.matmul(fv_x1,W_bi),tf.transpose(fv_x2))),name='scores')\n",
    "\n",
    "scores = run_scores(final_state_x1, final_state_x2, x1_to_x2_attvec, x2_to_x1_attvec)\n",
    "predictions = tf.cast(tf.round(scores), tf.int32, name='predictions') \n",
    "\n",
    "with tf.name_scope('Loss'):\n",
    "    losses = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(input_y, tf.float32), logits=scores)\n",
    "    loss = tf.reduce_mean(losses)\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "    correct_predictions = tf.equal(predictions, input_y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32), name='accuracy')\n",
    "    \n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "optimizer = tf.train.AdamOptimizer(1e-5)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step, name='train_op')\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1\n",
      "\n",
      "\n",
      "  batch loss & accuracy at step 423500: <0.5032082796096802, 1.0>\n",
      "  batch loss & accuracy at step 423600: <0.5042983293533325, 1.0>\n",
      "  batch loss & accuracy at step 423700: <0.5061130523681641, 0.9964788556098938>\n",
      "  batch loss & accuracy at step 423800: <0.5115534663200378, 0.984375>\n",
      "  batch loss & accuracy at step 423900: <0.5098389387130737, 0.9876033067703247>\n",
      "  batch loss & accuracy at step 424000: <0.5089454054832458, 0.9897260069847107>\n",
      "  batch loss & accuracy at step 424100: <0.5081626772880554, 0.9912280440330505>\n",
      "  batch loss & accuracy at step 424200: <0.5080155730247498, 0.9910714030265808>\n",
      "  batch loss & accuracy at step 424300: <0.507568895816803, 0.9920814633369446>\n",
      "  batch loss & accuracy at step 424400: <0.5086782574653625, 0.9888211488723755>\n",
      "  batch loss & accuracy at step 424500: <0.5087453722953796, 0.9889298677444458>\n",
      "  batch loss & accuracy at step 424600: <0.5082774758338928, 0.9898648858070374>\n",
      "  batch loss & accuracy at step 424700: <0.5083699226379395, 0.9898753762245178>\n",
      "  batch loss & accuracy at step 424800: <0.507996678352356, 0.990606963634491>\n",
      "  batch loss & accuracy at step 424900: <0.5076737999916077, 0.9912399053573608>\n",
      "  batch loss & accuracy at step 425000: <0.507391631603241, 0.9917929172515869>\n",
      "  batch loss & accuracy at step 425100: <0.5072242617607117, 0.9922803044319153>\n",
      "  batch loss & accuracy at step 425200: <0.5069988965988159, 0.9927130341529846>\n",
      "  batch loss & accuracy at step 425300: <0.5068110227584839, 0.9930998086929321>\n",
      "  batch loss & accuracy at step 425400: <0.5066519379615784, 0.9934476017951965>\n",
      "  batch loss & accuracy at step 425500: <0.5064864754676819, 0.9937620162963867>\n",
      "  batch loss & accuracy at step 425600: <0.5071881413459778, 0.9926739931106567>\n",
      "  batch loss & accuracy at step 425700: <0.507017970085144, 0.9929947257041931>\n",
      "  batch loss & accuracy at step 425800: <0.5068586468696594, 0.9932885766029358>\n",
      "  batch loss & accuracy at step 425900: <0.506711483001709, 0.9935587644577026>\n",
      "  batch loss & accuracy at step 426000: <0.5065758228302002, 0.9938080310821533>\n",
      "  batch loss & accuracy at step 426100: <0.5064502358436584, 0.9940387606620789>\n",
      "  batch loss & accuracy at step 426200: <0.5065930485725403, 0.9938936829566956>\n",
      "  batch loss & accuracy at step 426300: <0.5064892768859863, 0.9941053986549377>\n",
      "  batch loss & accuracy at step 426400: <0.5065872073173523, 0.9939678311347961>\n",
      "  batch loss & accuracy at step 426500: <0.5065630078315735, 0.994163453578949>\n",
      "Stopped!\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 50\n",
    "NUM_BATCHES = 1000\n",
    "VERBOSE = 100\n",
    "\n",
    "try:\n",
    "    loss_track, accuracy_track = [], []\n",
    "    for e in range(NUM_EPOCHS):\n",
    "        print('Epoch ', e+1)\n",
    "        print('\\n')\n",
    "        curr_loss_track, curr_accuracy_track = [], []\n",
    "        for _ in range(NUM_BATCHES):\n",
    "            batch_x1, batch_x2, batch_y = get_batch()\n",
    "            for x1, x2, y in zip(batch_x1,batch_x2,batch_y):\n",
    "                x1,x1_len = batch([x1])\n",
    "                x2,x2_len = batch([x2])\n",
    "                y = [y]\n",
    "                fd = {input_x1:x1, input_x1_length:x1_len,\n",
    "                      input_x2:x2, input_x2_length:x2_len,\n",
    "                      input_y:y,\n",
    "                      keep_prob:KEEP_PROB}\n",
    "                _, step, loss_, accuracy_ = sess.run([train_op, global_step, loss, accuracy], feed_dict=fd)\n",
    "                curr_loss_track.append(loss_)\n",
    "                curr_accuracy_track.append(accuracy_)\n",
    "                if step%VERBOSE==0:\n",
    "                    print('  batch loss & accuracy at step {}: <{}, {}>'.format(step, np.mean(curr_loss_track), \n",
    "                                                                                      np.mean(curr_accuracy_track)))\n",
    "            loss_track += curr_loss_track\n",
    "            accuracy_track += curr_accuracy_track\n",
    "except KeyboardInterrupt:\n",
    "    print('Stopped!')            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import colorama\n",
    "from colorama import Fore, Back, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(x1, x2):\n",
    "    x1,x1_len = batch([x1])\n",
    "    x2,x2_len = batch([x2])\n",
    "    fd = {input_x1:x1, input_x1_length:x1_len,\n",
    "          input_x2:x2, input_x2_length:x2_len,\n",
    "          keep_prob:KEEP_PROB}\n",
    "    conf = sess.run(scores, feed_dict=fd)\n",
    "    return 1-conf[0]\n",
    "\n",
    "def get_rand_mixture():\n",
    "    type1, type2 = np.random.choice(TYPES, 2, replace=False)\n",
    "    _, _, doc_mix, doc_lbs = get_mixture(type1, type2)\n",
    "    return doc_mix, doc_lbs\n",
    "\n",
    "def flip_clust(clust):\n",
    "    return np.array([0 if i==1 else 1 for i in clust])\n",
    "\n",
    "def clust_accuracy(true, pred):\n",
    "    return max(accuracy_score(true, pred),\n",
    "               accuracy_score(true, flip_clust(pred)))\n",
    "\n",
    "def rand_evaluate(k=1000):\n",
    "    accuracies = []\n",
    "    for _ in range(k):\n",
    "        doc_mix, doc_lbs = get_rand_mixture()\n",
    "        doc_mix_sq, _ = batch(doc_mix)\n",
    "        doc_mix_sq = doc_mix_sq.T\n",
    "        doc_mix_clust = linkage(doc_mix_sq, method='average', metric=dist)\n",
    "        doc_prd = fcluster(doc_mix_clust, 2, criterion='maxclust') - 1 # label adjusted.\n",
    "        accuracies.append(clust_accuracy(doc_lbs, doc_prd))  \n",
    "    print('Average accuracy of {} samples = {}'.format(k, np.mean(accuracies)))\n",
    "\n",
    "def demo_evaluate(doc_mix, doc_lbs):\n",
    "    doc_mix_sq, _ = batch(doc_mix)\n",
    "    doc_mix_sq = doc_mix_sq.T\n",
    "    doc_mix_clust = linkage(doc_mix_sq, method='average', metric=dist)\n",
    "    doc_prd = fcluster(doc_mix_clust, 2, criterion='maxclust') - 1 # label adjusted.\n",
    "    acc = clust_accuracy(doc_lbs, doc_prd)\n",
    "    print('Clustering accuracy = {}'.format(acc))\n",
    "    print('\\n')\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.title('Hierarchical Clustering Dendrogram')\n",
    "    plt.xlabel('sample index')\n",
    "    plt.ylabel('distance')\n",
    "    dendrogram(\n",
    "        doc_mix_clust,\n",
    "        leaf_rotation=90.,  # rotates the x axis labels\n",
    "        leaf_font_size=15.,  # font size for the x axis labels\n",
    "    )\n",
    "    plt.show() \n",
    "    print('id| True | Pred | Sentence')\n",
    "    for i,(label,pred_label,code) in enumerate(list(zip(doc_lbs,doc_prd,doc_mix))):\n",
    "        if label==0:\n",
    "            print('\\033[1;37;40m {} | {}    | {}    | {}'.format(i,label,pred_label,to_sent(code)))\n",
    "        else:\n",
    "            print('\\033[1;30;47m {} | {}    | {}    | {}'.format(i,label,pred_label,to_sent(code)))\n",
    "    print('\\n' + Style.RESET_ALL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering accuracy = 1.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAB9YAAANVCAYAAAAtFBVGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2aeb42bbc630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id| True | Pred | Sentence\n",
      "\u001b[1;37;40m 0 | 0    | 0    | ['pear', 'tomato', 'share2', 'grape', 'share1', 'share2', 'tomato', 'tomato', 'pear', 'grape', 'strawberry', 'grape', 'share2']\n",
      "\u001b[1;37;40m 1 | 0    | 0    | ['share2', 'share1', 'tomato', 'strawberry', 'grape', 'pear']\n",
      "\u001b[1;37;40m 2 | 0    | 0    | ['apple', 'strawberry', 'pear', 'apple', 'share1', 'share2', 'apple', 'apple', 'grape', 'apple']\n",
      "\u001b[1;30;47m 3 | 1    | 1    | ['lake', 'hill', 'valley', 'lake', 'share1', 'valley', 'share2', 'share1', 'share2', 'share1']\n",
      "\u001b[1;37;40m 4 | 0    | 0    | ['grape', 'share2', 'tomato', 'pear', 'apple', 'strawberry', 'strawberry', 'tomato']\n",
      "\u001b[1;30;47m 5 | 1    | 1    | ['valley', 'hill', 'hill', 'mountain', 'mountain', 'lake', 'share1', 'river', 'mountain', 'river', 'mountain']\n",
      "\u001b[1;30;47m 6 | 1    | 1    | ['hill', 'river', 'share2', 'share1', 'hill', 'lake', 'mountain', 'valley', 'river']\n",
      "\u001b[1;30;47m 7 | 1    | 1    | ['mountain', 'hill', 'lake', 'share1', 'mountain', 'mountain', 'valley', 'mountain', 'mountain', 'share1', 'share1']\n",
      "\u001b[1;37;40m 8 | 0    | 0    | ['share1', 'strawberry', 'strawberry', 'grape', 'grape', 'tomato', 'share1']\n",
      "\u001b[1;30;47m 9 | 1    | 1    | ['hill', 'mountain', 'river', 'hill', 'mountain', 'hill', 'lake', 'valley', 'lake', 'lake', 'river', 'lake']\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "demo_evaluate(*get_rand_mixture())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy of 1000 samples = 0.8031999999999999\n"
     ]
    }
   ],
   "source": [
    "rand_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cProfile\n",
    "# dm, dl = get_rand_mixture()\n",
    "# cProfile.run('demo_evaluate(dm,dl)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
