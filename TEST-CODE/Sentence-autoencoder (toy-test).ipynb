{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/work/04233/sw33286/AIDA-SCRIPTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import random\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "from tensorflow.contrib.layers import safe_embedding_lookup_sparse as embedding_lookup_unique\n",
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple, GRUCell\n",
    "\n",
    "from helpers import Indexer\n",
    "from helpers import batch\n",
    "# from nltk.corpus import brown\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = ['one','two','three','four','five',\n",
    "         'six','seven','eight','nine','ten']\n",
    "indexer = Indexer()\n",
    "indexer.get_index('PAD')\n",
    "indexer.get_index('EOS')\n",
    "for word in VOCAB:\n",
    "    indexer.get_index(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM_LEN = 3\n",
    "TO_LEN = 8\n",
    "\n",
    "def generate_sent(from_len, to_len):\n",
    "    length = np.random.randint(from_len, to_len)\n",
    "    return np.random.choice(VOCAB, length)\n",
    "\n",
    "def to_code(sent):\n",
    "    return [indexer.get_index(word) for word in sent]\n",
    "\n",
    "def to_sent(code):\n",
    "    return list(map(lambda w_idx:indexer.get_object(w_idx), code))\n",
    "    \n",
    "def get_batch(n, from_len=FROM_LEN, to_len=TO_LEN):\n",
    "    return [to_code(generate_sent(from_len,to_len)) for _ in range(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "batch_size = 10\n",
    "vocab_size = len(indexer)\n",
    "embed_size = 20\n",
    "encoder_hidden_size = 10\n",
    "decoder_hidden_size = encoder_hidden_size*2\n",
    "\n",
    "# attention = True\n",
    "# bidirectional = True\n",
    "\n",
    "encoder_cell = LSTMCell(encoder_hidden_size)\n",
    "decoder_cell = LSTMCell(decoder_hidden_size)\n",
    "\n",
    "encoder_inputs = tf.placeholder(tf.int32, [None, None], name='encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(tf.int32, [None,], name='encoder_inputs_length')\n",
    "decoder_targets = tf.placeholder(tf.int32, [None, None], name='decoder_targets')\n",
    "decoder_targets_length = tf.placeholder(tf.int32, [None,], name='decoder_targets_length')\n",
    "\n",
    "with tf.name_scope('DecoderTrainFeeds'):\n",
    "    sequence_size, batch_size_ = tf.unstack(tf.shape(decoder_targets))\n",
    "    EOS_SLICE = tf.ones([1, batch_size_], dtype=tf.int32) * indexer.get_index('EOS')\n",
    "    PAD_SLICE = tf.ones([1, batch_size_], dtype=tf.int32) * indexer.get_index('PAD')\n",
    "    decoder_train_inputs = tf.concat([EOS_SLICE, decoder_targets], axis=0) # [max-time+1, batch_size]\n",
    "    decoder_train_length = decoder_targets_length + 1\n",
    "    decoder_train_targets = tf.concat([decoder_targets, PAD_SLICE], axis=0)\n",
    "    decoder_train_targets_seq_len,_ = tf.unstack(tf.shape(decoder_train_targets))\n",
    "    decoder_train_targets_eos_mask = tf.one_hot(decoder_train_length-1,\n",
    "                                                decoder_train_targets_seq_len,\n",
    "                                                on_value=indexer.get_index('EOS'), \n",
    "                                                off_value=indexer.get_index('PAD'),\n",
    "                                                dtype=tf.int32)\n",
    "    decoder_train_targets_eos_mask = tf.transpose(decoder_train_targets_eos_mask, [1,0])\n",
    "    decoder_train_targets = tf.add(decoder_train_targets,\n",
    "                                   decoder_train_targets_eos_mask)\n",
    "    loss_weights = tf.ones([\n",
    "        batch_size,\n",
    "        tf.reduce_max(decoder_train_length)\n",
    "    ], dtype=tf.float32, name='loss_weights')\n",
    "    \n",
    "with tf.variable_scope('embedding') as scope:\n",
    "    embedding_matrix = tf.get_variable('embedding_matrix', [vocab_size, embed_size], \n",
    "                                       initializer=tf.contrib.layers.xavier_initializer())\n",
    "#     glove_feed = tf.placeholder(tf.float32, glove_embs.shape)\n",
    "#     glove_init = embedding_matrix.assign(glove_feed)\n",
    "    encoder_inputs_embedded = tf.nn.embedding_lookup(embedding_matrix, encoder_inputs)\n",
    "    decoder_train_inputs_embedded = tf.nn.embedding_lookup(embedding_matrix, decoder_train_inputs)\n",
    "    \n",
    "with tf.variable_scope('BidirectionalEncoder') as scope:\n",
    "    encoder_cell = LSTMCell(encoder_hidden_size)\n",
    "    ((encoder_fw_outputs,encoder_bw_outputs),\n",
    "     (encoder_fw_state,encoder_bw_state)) = (\n",
    "        tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                        cell_bw=encoder_cell,\n",
    "                                        inputs=encoder_inputs_embedded,\n",
    "                                        sequence_length=encoder_inputs_length,\n",
    "                                        dtype=tf.float32, time_major=True)\n",
    "    )\n",
    "    encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "    if isinstance(encoder_fw_state, LSTMStateTuple):\n",
    "        encoder_state_c = tf.concat((encoder_fw_state.c, encoder_bw_state.c), 1, name='bidirectional_concat_c')\n",
    "        encoder_state_h = tf.concat((encoder_fw_state.h, encoder_bw_state.h), 1, name='bidirectional_concat_h')\n",
    "        encoder_state = LSTMStateTuple(c=encoder_state_c, h=encoder_state_h)\n",
    "    elif isinstance(encoder_fw_state, tf.Tensor):\n",
    "        encoder_state = tf.concat((encoder_fw_state, encoder_bw_state), 1, name='bidirectional_concat')\n",
    "        \n",
    "with tf.variable_scope('Decoder') as scope:\n",
    "    def output_fn(outputs):\n",
    "        return tf.contrib.layers.linear(outputs, vocab_size, scope=scope)\n",
    "    attention_states = tf.transpose(encoder_outputs, [1,0,2]) # [batch_size,max-time,hidden_size]\n",
    "    (attention_keys,\n",
    "     attention_values,\n",
    "     attention_score_fn,\n",
    "     attention_construct_fn) = seq2seq.prepare_attention(\n",
    "        attention_states=attention_states,\n",
    "        attention_option='bahdanau',\n",
    "        num_units=decoder_hidden_size\n",
    "    )\n",
    "    decoder_fn_train = seq2seq.attention_decoder_fn_train(\n",
    "        encoder_state=encoder_state,\n",
    "        attention_keys=attention_keys,\n",
    "        attention_values=attention_values,\n",
    "        attention_score_fn=attention_score_fn,\n",
    "        attention_construct_fn=attention_construct_fn,\n",
    "        name='attention_decoder'\n",
    "    )\n",
    "    decoder_fn_inference = seq2seq.attention_decoder_fn_inference(\n",
    "        output_fn=output_fn,\n",
    "        encoder_state=encoder_state,\n",
    "        attention_keys=attention_keys,\n",
    "        attention_values=attention_values,\n",
    "        attention_score_fn=attention_score_fn,\n",
    "        attention_construct_fn=attention_construct_fn,\n",
    "        embeddings=embedding_matrix,\n",
    "        start_of_sequence_id=indexer.get_index('EOS'),\n",
    "        end_of_sequence_id=indexer.get_index('EOS'),\n",
    "        maximum_length=tf.reduce_max(encoder_inputs_length) + 3,\n",
    "        num_decoder_symbols=vocab_size\n",
    "    )\n",
    "    (decoder_outputs_train,\n",
    "     decoder_state_train,\n",
    "     decoder_context_state_train) = (\n",
    "        seq2seq.dynamic_rnn_decoder(\n",
    "            cell=decoder_cell,\n",
    "            decoder_fn=decoder_fn_train,\n",
    "            inputs=decoder_train_inputs_embedded,\n",
    "            sequence_length=decoder_train_length,\n",
    "            time_major=True,\n",
    "            scope=scope\n",
    "        )\n",
    "    )\n",
    "    decoder_logits_train = output_fn(decoder_outputs_train)\n",
    "    decoder_prediction_train = tf.argmax(decoder_logits_train, axis=-1, name='decoder_prediction_train')\n",
    "    scope.reuse_variables()\n",
    "    (decoder_logits_inference,\n",
    "     decoder_state_inference,\n",
    "     decoder_context_state_inference) = (\n",
    "        seq2seq.dynamic_rnn_decoder(\n",
    "            cell=decoder_cell,\n",
    "            decoder_fn=decoder_fn_inference,\n",
    "            time_major=True,\n",
    "            scope=scope\n",
    "        )\n",
    "    )\n",
    "    decoder_prediction_inference = tf.argmax(decoder_logits_inference, axis=-1, name='decoder_prediction_inference')\n",
    "    \n",
    "logits = tf.transpose(decoder_logits_train, [1,0,2])\n",
    "targets = tf.transpose(decoder_train_targets, [1,0])\n",
    "loss = seq2seq.sequence_loss(logits=logits, targets=targets, weights=loss_weights)\n",
    "train_op = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_inputs(input_seq, target_seq):\n",
    "    inputs_, inputs_length_ = batch(input_seq)\n",
    "    targets_, targets_length_ = batch(target_seq)\n",
    "    return {\n",
    "        encoder_inputs: inputs_,\n",
    "        encoder_inputs_length: inputs_length_,\n",
    "        decoder_targets: targets_,\n",
    "        decoder_targets_length: targets_length_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 0.4709915220737457\n",
      "  sample 1:\n",
      "    enc input           > ['seven', 'two', 'two', 'one', 'eight', 'five']\n",
      "    dec train predicted > ['seven', 'two', 'two', 'one', 'eight', 'five', 'EOS']\n",
      "  sample 2:\n",
      "    enc input           > ['five', 'nine', 'seven', 'eight', 'one', 'six']\n",
      "    dec train predicted > ['five', 'nine', 'seven', 'eight', 'one', 'six', 'EOS']\n",
      "  sample 3:\n",
      "    enc input           > ['eight', 'one', 'nine']\n",
      "    dec train predicted > ['eight', 'one', 'nine', 'EOS']\n",
      "\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.4195615351200104\n",
      "  sample 1:\n",
      "    enc input           > ['four', 'seven', 'nine', 'ten']\n",
      "    dec train predicted > ['four', 'seven', 'nine', 'ten', 'EOS']\n",
      "  sample 2:\n",
      "    enc input           > ['one', 'nine', 'four']\n",
      "    dec train predicted > ['one', 'nine', 'four', 'EOS']\n",
      "  sample 3:\n",
      "    enc input           > ['five', 'five', 'one', 'eight', 'six', 'one']\n",
      "    dec train predicted > ['five', 'one', 'one', 'eight', 'six', 'one', 'EOS']\n",
      "\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.43812695145606995\n",
      "  sample 1:\n",
      "    enc input           > ['two', 'ten', 'six']\n",
      "    dec train predicted > ['two', 'ten', 'six', 'EOS']\n",
      "  sample 2:\n",
      "    enc input           > ['three', 'seven', 'four', 'five', 'nine']\n",
      "    dec train predicted > ['three', 'seven', 'four', 'five', 'nine', 'EOS']\n",
      "  sample 3:\n",
      "    enc input           > ['two', 'four', 'two', 'one', 'four', 'one', 'one']\n",
      "    dec train predicted > ['seven', 'four', 'two', 'one', 'three', 'one', 'one', 'EOS']\n",
      "\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.32999444007873535\n",
      "  sample 1:\n",
      "    enc input           > ['seven', 'four', 'eight']\n",
      "    dec train predicted > ['seven', 'four', 'eight', 'EOS']\n",
      "  sample 2:\n",
      "    enc input           > ['eight', 'four', 'six', 'two', 'two']\n",
      "    dec train predicted > ['eight', 'four', 'six', 'two', 'two', 'EOS']\n",
      "  sample 3:\n",
      "    enc input           > ['two', 'ten', 'seven', 'eight', 'ten', 'four', 'nine']\n",
      "    dec train predicted > ['two', 'ten', 'seven', 'eight', 'ten', 'four', 'nine', 'EOS']\n",
      "\n",
      "\n",
      "batch 4000\n",
      "  minibatch loss: 0.30930083990097046\n",
      "  sample 1:\n",
      "    enc input           > ['seven', 'ten', 'two', 'three']\n",
      "    dec train predicted > ['seven', 'ten', 'two', 'three', 'EOS']\n",
      "  sample 2:\n",
      "    enc input           > ['two', 'ten', 'eight', 'three', 'six', 'seven', 'eight']\n",
      "    dec train predicted > ['two', 'ten', 'eight', 'three', 'six', 'seven', 'four', 'EOS']\n",
      "  sample 3:\n",
      "    enc input           > ['eight', 'four', 'four', 'one', 'nine', 'three']\n",
      "    dec train predicted > ['eight', 'four', 'four', 'one', 'nine', 'three', 'EOS']\n",
      "\n",
      "\n",
      "batch 5000\n",
      "  minibatch loss: 0.2554932236671448\n",
      "  sample 1:\n",
      "    enc input           > ['six', 'eight', 'six', 'two', 'seven', 'eight', 'seven']\n",
      "    dec train predicted > ['six', 'eight', 'six', 'two', 'seven', 'eight', 'seven', 'EOS']\n",
      "  sample 2:\n",
      "    enc input           > ['six', 'two', 'ten', 'seven', 'six', 'two']\n",
      "    dec train predicted > ['six', 'two', 'ten', 'seven', 'six', 'two', 'EOS']\n",
      "  sample 3:\n",
      "    enc input           > ['three', 'six', 'nine']\n",
      "    dec train predicted > ['three', 'six', 'nine', 'EOS']\n",
      "\n",
      "\n",
      "batch 6000\n",
      "  minibatch loss: 0.19502422213554382\n",
      "  sample 1:\n",
      "    enc input           > ['ten', 'three', 'five', 'five', 'ten']\n",
      "    dec train predicted > ['ten', 'three', 'five', 'five', 'ten', 'EOS']\n",
      "  sample 2:\n",
      "    enc input           > ['ten', 'three', 'six']\n",
      "    dec train predicted > ['ten', 'three', 'six', 'EOS']\n",
      "  sample 3:\n",
      "    enc input           > ['ten', 'ten', 'eight', 'seven']\n",
      "    dec train predicted > ['ten', 'ten', 'eight', 'seven', 'EOS']\n",
      "\n",
      "\n",
      "batch 7000\n",
      "  minibatch loss: 0.160684734582901\n",
      "  sample 1:\n",
      "    enc input           > ['three', 'five', 'two']\n",
      "    dec train predicted > ['three', 'five', 'two', 'EOS']\n",
      "  sample 2:\n",
      "    enc input           > ['seven', 'eight', 'three']\n",
      "    dec train predicted > ['seven', 'eight', 'three', 'EOS']\n",
      "  sample 3:\n",
      "    enc input           > ['eight', 'eight', 'six', 'two']\n",
      "    dec train predicted > ['eight', 'eight', 'six', 'two', 'EOS']\n",
      "\n",
      "\n",
      "batch 8000\n",
      "  minibatch loss: 0.12935452163219452\n",
      "  sample 1:\n",
      "    enc input           > ['seven', 'two', 'eight', 'two', 'nine']\n",
      "    dec train predicted > ['seven', 'two', 'eight', 'two', 'nine', 'EOS']\n",
      "  sample 2:\n",
      "    enc input           > ['ten', 'nine', 'five']\n",
      "    dec train predicted > ['ten', 'nine', 'five', 'EOS']\n",
      "  sample 3:\n",
      "    enc input           > ['ten', 'four', 'two', 'ten', 'one', 'one']\n",
      "    dec train predicted > ['ten', 'four', 'two', 'ten', 'one', 'one', 'EOS']\n",
      "\n",
      "\n",
      "batch 9000\n",
      "  minibatch loss: 0.10454466193914413\n",
      "  sample 1:\n",
      "    enc input           > ['eight', 'eight', 'nine']\n",
      "    dec train predicted > ['eight', 'eight', 'nine', 'EOS']\n",
      "  sample 2:\n",
      "    enc input           > ['nine', 'three', 'ten', 'two', 'eight', 'five', 'one']\n",
      "    dec train predicted > ['nine', 'three', 'ten', 'two', 'eight', 'five', 'one', 'EOS']\n",
      "  sample 3:\n",
      "    enc input           > ['six', 'eight', 'one', 'ten', 'four', 'three', 'nine']\n",
      "    dec train predicted > ['six', 'eight', 'one', 'ten', 'four', 'three', 'nine', 'EOS']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "num_batches = 10000\n",
    "verbose = 1000\n",
    "try:\n",
    "    for b in range(num_batches):\n",
    "        batch_inputs = get_batch(batch_size)\n",
    "        fd = make_train_inputs(batch_inputs, batch_inputs)\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "        if b==0 or b%verbose==0:\n",
    "            print('batch {}'.format(b))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            for i,(e_in, dt_pred) in enumerate(zip(\n",
    "                fd[encoder_inputs].T, # [max-time,batch_size] -> [batch_size,max-time]\n",
    "                sess.run(decoder_prediction_train, fd).T\n",
    "            )):\n",
    "                print('  sample {}:'.format(i+1))\n",
    "                print('    enc input           > {}'.format([w for w in to_sent(e_in) if w!='PAD']))\n",
    "                print('    dec train predicted > {}'.format([w for w in to_sent(dt_pred) if w!='PAD']))\n",
    "                if i>=2:\n",
    "                    break\n",
    "            print('\\n')\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
